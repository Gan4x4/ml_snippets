{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения установим Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Задачу с Kaggle. Цель: обучить модель отличать подлиные подписи:\n",
    "\n",
    "[kaggle signature verification dataset](https://www.kaggle.com/robinreni/signature-verification-dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://ml.gan4x4.ru/msu/dep-1.9/Exercises/EX11/signature_verification_dataset.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет состоит из набора сканов подписей разложенным по папкам\n",
    "\n",
    "\n",
    "> id1\n",
    "\n",
    "> id1_forg\n",
    "\n",
    "> id2\n",
    "\n",
    "> id2_forg\n",
    "\n",
    "> ...\n",
    "\n",
    "\n",
    "в папке id1 содержатся сканы полинных подписей одного человека. В папке id1_forg содержатся сканы поддельных подписей того же человека.\n",
    "\n",
    "В папках с перфиксом id2, id2_forg - настоящие и поддельные подписи другого человека и.т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data :\n",
    "\n",
    "Фрагмент датасета достаточный для выполнения задания доступен по ссылке::  http://edunet.kea.su/repo/src/L11_Transfer_learning/sign_mini.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ml.gan4x4.ru/msu/dep-1.9/datasets/sign_mini.zip\n",
    "!unzip sign_mini.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create standart dataset\n",
    "Класс датасета.\n",
    "\n",
    "Для использования TripletLoss или CosineEmbeddingLoss\n",
    "нам нужно получать тройки. Для ArcFace или CE with SoftMax нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((96, 96)),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.9409, 0.1078),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(\"sign_data_mini/train\", transform=transform)\n",
    "val_dataset = ImageFolder(\"sign_data_mini/test\", transform=transform)\n",
    "print(train_dataset)\n",
    "print(\"Classes count\", len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "dataiter = iter(val_dataloader)\n",
    "batch = next(dataiter)  # img1, label\n",
    "images, labels = batch\n",
    "\n",
    "grid = utils.make_grid(images, nrow=8)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 15)\n",
    "plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим размер batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = resnet18()\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
    "    model.fc = nn.Linear(512, 64)\n",
    "    # if return_embedding:\n",
    "    #  model.fc = nn.Identity()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = get_model()\n",
    "# print(model)\n",
    "summary(model, (1, 96, 96), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArcFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Lightning module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все отличие от классического цикла обучени состоит в том что вместо меток классов модель возвращает эмбеддинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMLMetricWrapper:\n",
    "    embeddings = None\n",
    "    labels = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.calc = AccuracyCalculator()\n",
    "        self.reset()\n",
    "\n",
    "    def compute(self):\n",
    "        accuracies = self.calc.get_accuracy(self.embeddings, self.labels)\n",
    "        return accuracies\n",
    "\n",
    "    def update(self, embeddings, labels):\n",
    "        self.labels = torch.cat((self.labels, labels.detach().cpu()), dim=0)\n",
    "        self.embeddings = torch.cat((self.embeddings, embeddings.detach().cpu()))\n",
    "\n",
    "    def reset(self):\n",
    "        self.embeddings = torch.empty((0, 64))\n",
    "        self.labels = torch.empty((0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "\n",
    "class Lit(L.LightningModule):\n",
    "    lr = 0.001\n",
    "\n",
    "    def __init__(self, model, criterion):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.metrics = PMLMetricWrapper()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        embeddings = self.model(x)\n",
    "        loss = self.criterion(embeddings, y)\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.metrics.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        embeddings = self.model(x)\n",
    "        self.metrics.update(embeddings, y)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        metrics = self.metrics.compute()\n",
    "        self.log(\"mAP\", metrics[\"mean_average_precision\"], prog_bar=True)\n",
    "\n",
    "        # return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss init\n",
    "Инициализируем  [ArcFaceLoss](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/#arcfaceloss)\n",
    "\n",
    "Для начала выясним длину эмбединга\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "out = model(torch.randn(1, 1, 96, 96))  # [1,64]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И создадим объект для loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do it without Lightning you must add .to(device) for loss object\n",
    "criterion = ArcFaceLoss(\n",
    "    num_classes=len(train_dataset.classes),  # because of linear layer inside\n",
    "    embedding_size=out.shape[1],\n",
    ")\n",
    "\n",
    "for name, p in criterion.named_parameters():\n",
    "    print(name, p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "model = get_model()\n",
    "lit_model = Lit(model, criterion)\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"ArcFace\")\n",
    "trainer = L.Trainer(max_epochs=20, logger=logger, log_every_n_steps=5)\n",
    "trainer.fit(\n",
    "    model=lit_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers, _ = loss_func.get_outliers(train_embeddings, train_labels.squeeze(1))\n",
    "# print(f\"There are {len(outliers)} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lit_model.metrics.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on forged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам интересно оценить как модель будет отличать именно поддельные подписи. Для того что бы получить все пары подписей придется написать свой код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание тренировочного и тестового датасета и даталоадера.\n",
    "В отличие варианта для визуализации к трансформациям добавилась нормализация.\n",
    "\n",
    "Этот блок можно модифицировать не требуется, но допускается.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from itertools import product\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, dir=None, transform=None):\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        self.classes = {1: \"Orginial\", -1: \"Forged\"}  # Change if need\n",
    "        self.data = self.get_pairs()\n",
    "        self.targets = self.get_targets()\n",
    "        self.cache = {}\n",
    "\n",
    "    def get_pairs(self):\n",
    "        pairs = []  # to store [orig, fake] or [orig,orig] pairs\n",
    "        persons = self.load_data()\n",
    "        for key in persons:\n",
    "            all_pairs = product(\n",
    "                persons[key][\"orig\"], persons[key][\"orig\"] + persons[key][\"forg\"]\n",
    "            )\n",
    "            # remove pairs with themselve\n",
    "            without_self_comparsion = list(filter(lambda x: x[0] != x[1], all_pairs))\n",
    "            pairs += without_self_comparsion\n",
    "        return pairs\n",
    "\n",
    "    def load_data(self):\n",
    "        all_paths = glob(f\"{self.dir}/**/*\")  # get all files path\n",
    "        persons = {}\n",
    "        # Group files by ID and type\n",
    "        for path in all_paths:\n",
    "            id, tp = PairDataset.parse(path)\n",
    "            if not id in persons:\n",
    "                persons[id] = {\"orig\": [], \"forg\": []}\n",
    "            persons[id][tp].append(path)\n",
    "        return persons\n",
    "\n",
    "    def get_targets(self):\n",
    "        targets = []\n",
    "        for pair in self.data:\n",
    "            _, tp = PairDataset.parse(pair[1])\n",
    "            label = -1 if tp == \"forg\" else 1\n",
    "            targets.append(label)\n",
    "        return targets\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(path):\n",
    "        folder = path.split(os.sep)[-2]\n",
    "        id = folder.split(\"_\")[0]\n",
    "        tp = \"forg\" if \"forg\" in path else \"orig\"\n",
    "        return id, tp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image0_path, image1_path = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        # Loading the images\n",
    "        img0 = self.load(image0_path)\n",
    "        img1 = self.load(image1_path)\n",
    "\n",
    "        return img0, img1, label\n",
    "\n",
    "    def load(self, path):\n",
    "        if path in self.cache:\n",
    "            img = self.cache[path]\n",
    "        else:\n",
    "            img = Image.open(path)  # .convert(\"L\")\n",
    "            self.cache[path] = img\n",
    "        # Apply image transformations\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pair_dataset = PairDataset(\"/content/sign_data_mini/test\", transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляр датасета и убедимся что данные загружаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Viewing the sample of images to check whether its loading properly\n",
    "print('\"1\" - подписи настоящие, \"-1\" - подделка')\n",
    "\n",
    "\n",
    "test_pair_dataloader = DataLoader(test_pair_dataset, batch_size=8, shuffle=False)\n",
    "dataiter = iter(test_pair_dataloader)\n",
    "\n",
    "example_batch = next(dataiter)  # img1, img2, label\n",
    "# display the data\n",
    "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
    "grid = utils.make_grid(concatenated)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.rcParams[\"figure.figsize\"] = (40, 20)\n",
    "plt.imshow(grid.permute(1, 2, 0).numpy())\n",
    "plt.show()\n",
    "\n",
    "print(example_batch[2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательный метод для подсчета accuracy с использованием порога и косинусного расстояния.\n",
    "\n",
    " Пара подписей считаются принадлежащими одному человеку, если косинусное расстояние между ними меньше порога по умолчанию равного 0.5. Иначе одна из подписей считается подделкой.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def validation(model, dl, threshold=0.5):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predicts = []\n",
    "    gt = []\n",
    "    sim = nn.CosineSimilarity()\n",
    "    for i, data in enumerate(dl):\n",
    "        x0, x1, label = data\n",
    "        out1 = model(x0.to(device))\n",
    "        out2 = model(x1.to(device))\n",
    "        dist = sim(out1, out2)\n",
    "        gt.append(label.flatten())\n",
    "        dist[dist < threshold] = -1  # Forged\n",
    "        dist[dist > threshold] = 1  # Original\n",
    "        predicts.append(dist.flatten().detach().cpu())\n",
    "    predicts = torch.cat(predicts).numpy().astype(float)\n",
    "    gt = torch.cat(gt).cpu().squeeze().detach().numpy()\n",
    "    return accuracy_score(predicts, gt)\n",
    "\n",
    "\n",
    "validation(model, test_pair_dataloader)  # accuracy ~ 0.5 on untrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно предположить что наиболее сложной задачей является именно различение поддельных подписей от настоящих. А при обучении они не так часто попадают в один batch. Можно использовать код вроде того что написан выше что бы в batch попадали только подписи одного человека и подделки. Но это тоже не идеальная стратегия так как у других людей могут встретиться похожие подписи.\n",
    "\n",
    "Более универсальным решением будет использование [Mainer](https://kevinmusgrave.github.io/pytorch-metric-learning/miners/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TritletLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "Так как у нас много классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_, labels = next(iter(train_dataloader))\n",
    "\n",
    "\n",
    "def show_classes(labels):\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    x, counts = labels.unique(return_counts=True)\n",
    "    plt.bar(np.array(train_dataset.classes)[x], height=counts)\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "show_classes(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если брать случайные батчи то у большинства объектов не находиться позитивных примеров. Когда датасет будет содержать еще большее количество объектов то ситуация усугубится.\n",
    "\n",
    "Поэтому Нужно формировать батчи(семплировать данные) так что бы в батче для каждого объекта были как положительные так и отрицательные примеры.\n",
    "\n",
    "\n",
    "В Pytorch есть механизм для семплирования: https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler\n",
    "\n",
    "Но он не поддерживает нужный нам алгоритм, поэтому воспользуемся сэмплером из библиотеки [PyTorch Metric Learning](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список сэмплеров:\n",
    "https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/\n",
    "\n",
    "\n",
    "Воспользуемся [MPerClassSampler](https://kevinmusgrave.github.io/pytorch-metric-learning/samplers/#mperclasssampler) этот семплер формирует батчи в которых фиксированное количество объектов из каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.samplers import MPerClassSampler\n",
    "\n",
    "\n",
    "mpc_sampler = MPerClassSampler(\n",
    "    labels=train_dataset.targets, m=3, length_before_new_iter=10000  # epoch end\n",
    ")\n",
    "\n",
    "train_dataloader_mpc_sampler = DataLoader(\n",
    "    train_dataset, batch_size=32, sampler=mpc_sampler\n",
    ")\n",
    "images, labels = next(iter(train_dataloader_mpc_sampler))  # img1, label\n",
    "\n",
    "\n",
    "show_classes(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятность того что batch попадут и поддельные и оригинальные подписи одного человека мала, увеличим размер batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_mpc_sampler = DataLoader(\n",
    "    train_dataset, batch_size=512, sampler=mpc_sampler, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miner\n",
    "\n",
    "Для использования TipletLoss нужно формировать тройки объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "\n",
    "miner = TripletMarginMiner(margin=0.2, type_of_triplets=\"all\")\n",
    "embeddings = model(images.to(device))\n",
    "indices_tuple = miner(embeddings, labels)\n",
    "print(len(indices_tuple))\n",
    "print(indices_tuple[0].shape)\n",
    "print(indices_tuple[1].shape)\n",
    "print(indices_tuple[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "\n",
    "\n",
    "class LitTriplet(Lit):\n",
    "    def __init__(self, model, criterion):\n",
    "        super().__init__(model, criterion)\n",
    "        self.miner = TripletMarginMiner(margin=0.2, type_of_triplets=\"all\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        embeddings = self.model(x)\n",
    "        indices = self.miner(embeddings, y)\n",
    "        loss = self.criterion(embeddings, y, indices)\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning.losses import TripletMarginLoss\n",
    "\n",
    "model = get_model()\n",
    "criterion = TripletMarginLoss(margin=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit = LitTriplet(model, criterion)\n",
    "lit.lr = 1e-5\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"Triplet\")\n",
    "trainer = L.Trainer(max_epochs=10, logger=logger, log_every_n_steps=5)\n",
    "trainer.fit(\n",
    "    model=lit,\n",
    "    train_dataloaders=train_dataloader_mpc_sampler,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on Forged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(model, test_pair_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline pair selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pair_dataset = PairDataset(\"/content/sign_data_mini/train\", transform)\n",
    "print(train_pair_dataset[0])\n",
    "train_pair_dataloader = DataLoader(\n",
    "    train_pair_dataset, batch_size=32, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCosine(Lit):\n",
    "    def __init__(self, model, criterion):\n",
    "        super().__init__(model, criterion)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x0, x1, y = batch\n",
    "        embeddings0 = self.model(x0)\n",
    "        embeddings1 = self.model(x1)\n",
    "        loss = self.criterion(embeddings0, embeddings1, y)\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pass\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "criterion = nn.CosineEmbeddingLoss(margin=-0)\n",
    "lit = LitCosine(model, criterion)\n",
    "lit.lr = 1e-5\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"ForgCosine\")\n",
    "trainer = L.Trainer(max_epochs=3, logger=logger, log_every_n_steps=5)\n",
    "trainer.fit(\n",
    "    model=lit, train_dataloaders=train_pair_dataloader, val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(model, test_pair_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном блоке нужно описать структуру модели.\n",
    "\n",
    "На вход модели поступают **два** одноканальных изображения а не одно. На выходе **два** вектора - признака (embeddings).\n",
    "\n",
    "Размер embedding подберите самостоятельно.\n",
    "\n",
    "\n",
    "\n",
    "Допускается использовать в качестве основы готовые модели из torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательный код для загрузки весов модели с диска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательный код для вывода изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img, text=None, should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.rcParams[\"figure.figsize\"] = (5, 10)\n",
    "    if text:\n",
    "        plt.text(\n",
    "            75,\n",
    "            8,\n",
    "            text,\n",
    "            style=\"italic\",\n",
    "            fontweight=\"bold\",\n",
    "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
    "        )\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация результатов сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_dataloader = DataLoader(test_pair_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Print the sample outputs to view its dissimilarity\n",
    "for i, batch in enumerate(vis_dataloader):\n",
    "    x0, x1, label_id = batch\n",
    "    output1 = model(x0.to(device))\n",
    "    output2 = model(x1.to(device))\n",
    "\n",
    "    eucledian_distance = F.pairwise_distance(output1, output2)\n",
    "    cosine_distance = F.cosine_similarity(output1, output2)\n",
    "    cos_norm = (cosine_distance + 1) / 2\n",
    "\n",
    "    for i in range(label_id.shape[0]):\n",
    "        concatenated = torch.cat((x0[i][0], x1[i][0]), 1)\n",
    "        label = test_pair_dataset.classes[label_id[i].item()]\n",
    "        imshow(\n",
    "            utils.make_grid(concatenated),\n",
    "            \"Dissimilarity(euc./cos./norm.): {:.2f}/{:.2f}/{:.2f} Label: {}\".format(\n",
    "                eucledian_distance[i].item(),\n",
    "                cosine_distance[i].item(),\n",
    "                cos_norm[i].item(),\n",
    "                label,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        print(\"Dissimilarity:\")\n",
    "        print(f\"Euclidean dist:  {eucledian_distance[i].item():.2f} [0 .. inf ]\")\n",
    "        print(f\"Cosine dist  {cosine_distance[i].item():.2f} [-1 .. 1]\")\n",
    "        print(f\"Normalized cos. dist  {cos_norm[i].item():.2f} [0 .. 1]\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
