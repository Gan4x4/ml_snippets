{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPI80sMtXQHH8AfNi1NEU5P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hI7bEYC5rRQJ"},"source":["# Импорты, функции из занятия"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q9iac73jrRQM"},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style(\"whitegrid\")\n","\n","from itertools import chain, product\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZeZh57A9rRQR"},"outputs":[],"source":["def plot_manifold(latent_r, labels=None, alpha=0.5):\n","    plt.figure(figsize=(10,10))\n","    if labels is None:\n","      plt.scatter(latent_r[:, 0], latent_r[:, 1], cmap=\"tab10\", alpha=0.9)\n","    else:\n","      plt.scatter(latent_r[:, 0], latent_r[:, 1], c=labels, cmap=\"tab10\", alpha=0.9)\n","      plt.colorbar()\n","    plt.show()\n","\n","def plot_digits(*args, invert_colors=True, digit_size=28, name=None):\n","    args = [x.squeeze() for x in args]\n","    n = min([x.shape[0] for x in args])\n","    figure = np.zeros((digit_size * len(args), digit_size * n))\n","\n","    for i in range(n):\n","        for j in range(len(args)):\n","            figure[j * digit_size: (j + 1) * digit_size,\n","                   i * digit_size: (i + 1) * digit_size] = args[j][i].squeeze()\n","\n","    if invert_colors:\n","        figure = 1 - figure\n","\n","    plt.figure(figsize=(2 * n, 2*len(args)))\n","    \n","    plt.imshow(figure, cmap='Greys_r', clim=(0, 1))\n","    \n","    plt.grid(False)\n","    ax = plt.gca()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    if name is not None:\n","        plt.savefig(name)\n","    plt.show()\n","\n","def train(enc, \n","          dec,\n","          loader, \n","          optimizer, \n","          single_pass_handler, \n","          loss_handler,\n","          epoch, \n","          log_interval=500):\n","    for batch_idx, (data, lab) in enumerate(loader):\n","        batch_size = data.size(0)\n","        optimizer.zero_grad()\n","        data = data.to(device)\n","        lab = lab.to(device)\n","\n","        latent, output = single_pass_handler(encoder, decoder, data, lab)\n","\n","        loss = loss_handler(data, output, latent)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(loader.dataset),\n","                100. * batch_idx / len(loader), loss.item()))\n","            \n","def ae_pass_handler(encoder, decoder, data, *args, **kwargs):\n","    latent = encoder(data)\n","    recons = decoder(latent)\n","    return latent, recons\n","\n","def ae_loss_handler(data, recons, *args, **kwargs):\n","    return F.binary_cross_entropy(recons, data)\n","\n","def run_eval(encoder, \n","             decoder, \n","             loader, \n","             single_pass_handler,\n","             return_real=True, \n","             return_recontr=True,\n","             return_latent=True,\n","             return_labels=True):\n","  \n","    if return_real:\n","        real = []\n","    if return_recontr:\n","        reconstr = []\n","    if return_latent:\n","        latent = []\n","    if return_labels:\n","        labels = []\n","    with torch.no_grad():\n","        for batch_idx, (data, lab) in enumerate(loader):  \n","            if return_labels:\n","                labels.append(lab.numpy())\n","            if return_real:\n","                real.append(data.numpy())\n","            \n","            data = data.to(device)\n","            lab = lab.to(device)\n","            rep, rec = single_pass_handler(encoder, decoder, data, lab)\n","            if return_latent:\n","                latent.append(rep.to('cpu').numpy())\n","            if return_recontr:\n","                reconstr.append(rec.to('cpu').numpy())\n","    \n","    result = {}\n","    if return_real:\n","        real = np.concatenate(real)\n","        result['real'] = real.squeeze()\n","    if return_latent:\n","        latent = np.concatenate(latent)\n","        result['latent'] = latent\n","    if return_recontr:\n","        reconstr = np.concatenate(reconstr)\n","        result['reconstr'] = reconstr.squeeze()\n","    if return_labels:\n","        labels = np.concatenate(labels)\n","        result['labels'] = labels\n","    return result\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UBWxcL0rRQX"},"outputs":[],"source":["#handson-ml2\n","\n","import matplotlib as mpl\n","def plot_percent_hist(ax, data, bins):\n","    counts, _ = np.histogram(data, bins=bins)\n","    widths = bins[1:] - bins[:-1]\n","    x = bins[:-1] + widths / 2\n","    ax.bar(x, counts / len(data), width=widths*0.8)\n","    ax.xaxis.set_ticks(bins)\n","    ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(\n","        lambda y, position: \"{}%\".format(int(np.round(100 * y)))))\n","    ax.grid(True)\n","\n","  \n","def plot_activations_histogram(activations, height=1, n_bins=10):\n","    activation_means = activations.mean(axis=0)\n","    \n","    mean = activation_means.mean()\n","    bins = np.linspace(0, 1, n_bins + 1)\n","\n","    fig, [ax1, ax2] = plt.subplots(figsize=(10, 3), nrows=1, ncols=2, sharey=True)\n","    plot_percent_hist(ax1, activations.ravel(), bins)\n","    ax1.plot([mean, mean], [0, height], \"k--\", label=\"Overall Mean = {:.2f}\".format(mean))\n","    ax1.legend(loc=\"upper center\", fontsize=14)\n","    ax1.set_xlabel(\"Activation\")\n","    ax1.set_ylabel(\"% Activations\")\n","    ax1.axis([0, 1, 0, height])\n","    plot_percent_hist(ax2, activation_means, bins)\n","    ax2.plot([mean, mean], [0, height], \"k--\")\n","    ax2.set_xlabel(\"Neuron Mean Activation\")\n","    ax2.set_ylabel(\"% Neurons\")\n","    ax2.axis([0, 1, 0, height])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKySv5bKrRQZ"},"outputs":[],"source":["class AddGaussianNoise:\n","    def __init__(self, mean=0., std=1.):\n","        self.std = std\n","        self.mean = mean\n","        \n","    def __call__(self, tensor):\n","        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n","    \n","    def __repr__(self):\n","        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLH_p4gprRQb"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, latent_size):\n","        super().__init__()\n","        self.latent_size = latent_size\n","        hidden_dims = [32, 64, 128, 256, 512]\n","\n","        # Build Encoder\n","        modules = []\n","        in_channels = 1\n","        for h_dim in hidden_dims[:-1]:\n","            modules.append(\n","                nn.Sequential(\n","                    nn.Conv2d(in_channels=in_channels,\n","                              out_channels=h_dim,\n","                              kernel_size=3, stride=2 , padding=1),\n","                    nn.BatchNorm2d(h_dim),\n","                    nn.LeakyReLU())\n","            )\n","            in_channels = h_dim\n","\n","        modules.append(\n","                nn.Sequential(\n","                    nn.Conv2d(in_channels=256,\n","                              out_channels=512,\n","                              kernel_size= 1),\n","                    nn.BatchNorm2d(512),\n","                    nn.LeakyReLU())\n","        )\n","        modules.append(nn.Flatten())\n","        modules.append(nn.Linear(hidden_dims[-1] * 4, latent_size))\n","\n","        self.encoder = nn.Sequential(*modules)      \n","    \n","    def forward(self, x):\n","        x = self.encoder(x)\n","        return x\n","        \n","class Decoder(nn.Module):\n","    def __init__(self, latent_size):\n","        super().__init__()\n","\n","        hidden_dims = [512, 256, 128, 64, 32]\n","        self.linear = nn.Linear(in_features=latent_size, \n","                                out_features=hidden_dims[0])\n","        \n","        modules = []\n","        for i in range(len(hidden_dims) - 1):\n","            modules.append(\n","                nn.Sequential(\n","                    nn.ConvTranspose2d(hidden_dims[i],\n","                                       hidden_dims[i + 1],\n","                                       kernel_size=3,\n","                                       stride=2,\n","                                       padding=1,\n","                                       output_padding=1),\n","                    nn.BatchNorm2d(hidden_dims[i + 1]),\n","                    nn.LeakyReLU())\n","            )\n","\n","\n","        modules.append(nn.Sequential(\n","                            nn.ConvTranspose2d(hidden_dims[-1],\n","                                               hidden_dims[-1],\n","                                               kernel_size=3,\n","                                               stride=2,\n","                                               padding=1,\n","                                               output_padding=1),\n","                            nn.BatchNorm2d(hidden_dims[-1]),\n","                            nn.LeakyReLU(),\n","                            nn.Conv2d(hidden_dims[-1], out_channels=1,\n","                                      kernel_size=7, padding=1),\n","                            nn.Sigmoid()))\n","\n","        self.decoder = nn.Sequential(*modules)   \n","\n","        \n","    def forward(self, x):\n","        x = self.linear(x)\n","        x = x.view(-1, 512, 1, 1)\n","        x = self.decoder(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"fgVAO6Q2rRQp"},"source":["# Задание 2. Разреженный autoencoder с KL-loss\n"]},{"cell_type":"markdown","metadata":{"id":"KHLwg6iCrRQp"},"source":["\n","\n","На занятии мы обсуждали, что разреженный автоэнкодер можно делать двумя путями - при помощи L1 и при помощи KL лосса. На занятии мы сделали с L1  лоссом. \n","\n","Ваша задача состоит в том, чтобы реализовать разреженный автоэнкодер с KL-лоссом. \n","\n","$$KL(P||Q) =  p(x) \\log \\dfrac {p(x)} {\\hat{p}(x) + \\epsilon} + (1 - p(x)) \\log \\dfrac {(1 - p(x))} {1 - \\hat{p}(x) + \\epsilon} $$\n","Обучите автоэнкодер с требованием, чтобы активировалось не более 10% нейронов. \n","\n","Учтите, что лосс надо считать по активациям, распределенным от 0 до 1 - то есть надо выполнить преобразование, аналогичное тому, что мы делали ранее\n","\n","\n","\n","Напоминаем, что в этом случае мы:\n"," 1. Усредняем активации по батчу\n"," 2. Для каждого нейрона таким образом получаем среднюю \"вероятность\" активироваться\n"," 3. Эта вероятность вряд ли будет в точности равна 0 или 1, но в выражение для KL-loss в знаменатель на всякий случай, добавляем малое число epsilon.\n"," 4. Подсчитанный лосс усредняем по всем нейронам слоя\n"," 5. Сделайте выводы\n","\n","\n","Постройте графики:\n","\n"," 1. Того, как восстанавливает автоэнкодер полученные изображения\n"," 2. Средних активаций для каждого класса \n"," 3. Распределения силы активаций в целом и средней силы активации каждого нейрона\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XqX4PPHnrRQq"},"source":["В следующих заданиях будет использоваться обычный MNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rbt4S6zTrRQq"},"outputs":[],"source":["\n","root = './data'\n","\n","train_set = dset.MNIST(root=root, \n","                       train=True, \n","                       transform=torchvision.transforms.ToTensor(),\n","                       download=True)\n","test_set = dset.MNIST(root=root, \n","                      train=False,\n","                      transform=torchvision.transforms.ToTensor(),\n","                      download=True)\n","\n","test_noise_set = dset.MNIST(root=root, \n","                      train=False,\n","                      transform=torchvision.transforms.Compose([\n","                          torchvision.transforms.ToTensor(),\n","                          AddGaussianNoise(0., 0.30)\n","                      ]),\n","                      download=True)\n","train_loader = torch.utils.data.DataLoader(\n","    train_set, \n","    batch_size=64,\n","    shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    train_set, \n","    batch_size=64,\n","    shuffle=False)\n","\n","test_noised_dataloader = torch.utils.data.DataLoader(\n","    torch.utils.data.Subset(test_noise_set, list(range(64))),\n","    batch_size=64, \n","    shuffle=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4czTpsw8rRQr"},"outputs":[],"source":["def to_01_activation(latent):\n","  activations = (torch.sigmoid(latent.abs()) - 0.5) * 2\n","  return activations\n","\n","def sparse_kl_loss(latent, p=0.10, eps=10e-5):\n","  activations = to_01_activation(latent)\n","  phat = activations.mean(axis=0) \n","  loss = p * torch.log(p/(phat + eps) ) + (1 - p) * torch.log( (1 - p) / (1 - phat + eps) )\n","  return loss.mean()\n","\n","\n","\n","def sparse_ae_pass_handler(encoder, decoder, data, *args, **kwargs):\n","    latent = encoder(data)\n","    recons = decoder(latent)\n","    return latent, recons\n","\n","def sparse_ae_loss_handler(data, recons, latent, beta=0.1, *args, **kwargs):\n","    return F.binary_cross_entropy(recons, data) + sparse_kl_loss(latent)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYD1vM4vrRQs"},"outputs":[],"source":["latent_size = 16 * 16\n","\n","learning_rate = 1e-4\n","encoder = Encoder(latent_size=latent_size)\n","decoder = Decoder(latent_size=latent_size)\n","\n","\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","\n","optimizer = optim.Adam(chain(encoder.parameters(),\n","                            decoder.parameters()\n","                           ),\n","                      lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTx0kTJerRQs"},"outputs":[],"source":["from functools import partial\n","for i in range(1, 6):\n","    train(enc=encoder, \n","      dec=decoder, \n","      optimizer=optimizer,\n","      loader=train_loader,\n","      epoch=i, \n","      single_pass_handler=sparse_ae_pass_handler,\n","      loss_handler=partial(sparse_ae_loss_handler, beta=0.01),\n","      log_interval=450)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Z_PzpYHrRQt"},"outputs":[],"source":["encoder = encoder.eval() \n","decoder = decoder.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dp36lWK0rRQt"},"outputs":[],"source":["run_res = run_eval(encoder, decoder, test_noised_dataloader, sparse_ae_pass_handler)\n","plot_digits(run_res['real'][0:9], run_res['reconstr'][0:9])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adJ4cTpxrRQu"},"outputs":[],"source":["run_res = run_eval(encoder, decoder, test_loader, sparse_ae_pass_handler)\n","_, axs = plt.subplots(nrows=2, ncols=5, figsize=(16, 5))\n","activations = to_01_activation(torch.from_numpy(run_res['latent'])).numpy()\n","for label in range(0, 10):\n","    \n","    figure = activations[run_res['labels'] == label].mean(axis=0)\n","    figure = figure.reshape(16, 16)\n","    ax = axs[label % 2, label % 5]\n","    ax.imshow(figure,\n","            cmap='Greys_r',\n","            clim=(0, 1))\n","    ax.grid(False)\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHl49DVFrRQu"},"outputs":[],"source":["plot_activations_histogram(activations, height=1.)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Db-xoKwXrRQv"},"source":["## Памятка для преподавателя\n","Студент должен получить в результате разреженный актоенкодер с целевой долей активаций. \n","Вывод - KL-loss удобнее при прочих равных"]}]}