{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве входа нужны маски из [MIDV-500](https://arxiv.org/abs/1807.05786)\n",
    "для предсказаний модель из 12 лекции: https://github.com/EPC-MSU/EduNet-secret/blob/dev-1.8/out/L12_Segmentation_Detection/EX12_Segmentation_sol.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Дополнительно) Сложно, долго, но интересно!\n",
    "\n",
    "Делаем свой сканер документов по фотографии. Цель хорошо описывается картинками:\n",
    "\n",
    "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/Exercises/EX12/Scaner.png\"  width=\"900\">\n",
    "\n",
    "Если решились выполнять задание, то для удобства сохраните модель из предыдущего задания, а лучше некоторый набор предсказанных изображений: исходное, оригинальная маска, предсказанная маска. (весь validation датасет, например)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подзадача 1.\n",
    "Используя маски, которые выдаёт модель, любыми алгоритмами найдите на масках углы документа (или границы документа).\n",
    "\n",
    "Большинство известных алгоритмов можно найти в opencv, например:\n",
    "* [Canny](https://docs.opencv.org/4.x/da/d22/tutorial_py_canny.html)\n",
    "* [Contour features](https://docs.opencv.org/4.6.0/dd/d49/tutorial_py_contour_features.html)\n",
    "* [Features harris](https://docs.opencv.org/4.x/dc/d0d/tutorial_py_features_harris.html)\n",
    "\n",
    "Рекомендуется перед применением алгоритмов [маску бинаризовать](https://docs.opencv.org/3.4/db/d8e/tutorial_threshold.html) по порогу: все пиксели выше порога сделать истинно белыми, а ниже - чёрными. (И проверить качество бинаризованных изображений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# cur_mask - numpy-array mask, values between 0 and 1\n",
    "# returns binarized mask as uint8 numpy array\n",
    "def binarize_mask(cur_mask, dilation_rad=5):\n",
    "    cur_mask = (np.clip(cur_mask, 0, 1) * 255.0).astype(np.uint8)\n",
    "    h, w = cur_mask.shape\n",
    "    # plt.imshow(cur_mask)\n",
    "\n",
    "    # Since ground truth values are 0 or 1 and network output may be outside of that,\n",
    "    # setting a constant threshold for ground truth is workable\n",
    "    _, cur_mask = cv.threshold(cur_mask, 128, 255, cv.THRESH_BINARY)\n",
    "    padded_mask = np.zeros(\n",
    "        (h + dilation_rad * 2 + 2, w + dilation_rad * 2 + 2), np.uint8\n",
    "    )\n",
    "    padded_mask[\n",
    "        dilation_rad + 1 : -dilation_rad - 1, dilation_rad + 1 : -dilation_rad - 1\n",
    "    ] = cur_mask\n",
    "\n",
    "    structuringElem = cv.getStructuringElement(\n",
    "        cv.MORPH_RECT, (dilation_rad, dilation_rad)\n",
    "    )\n",
    "    padded_mask = cv.dilate(padded_mask, structuringElem)\n",
    "\n",
    "    # Filling the image\n",
    "    # based on https://learnopencv.com/filling-holes-in-an-image-using-opencv-python-c/\n",
    "    mask_floodfill = padded_mask.copy()\n",
    "    mask = np.zeros((h + dilation_rad * 2 + 4, w + dilation_rad * 2 + 4), np.uint8)\n",
    "    mask_floodfill = cv.floodFill(\n",
    "        mask_floodfill, mask, (0, 0), 255, flags=cv.FLOODFILL_MASK_ONLY\n",
    "    )[1]\n",
    "    mask = 255 - 255 * mask\n",
    "    mask = cv.erode(mask, structuringElem)\n",
    "    # plt.imshow(cur_mask)\n",
    "    return mask[\n",
    "        dilation_rad + 2 : -dilation_rad - 2, dilation_rad + 2 : -dilation_rad - 2\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corners(mask, dilation_size=3):\n",
    "    # Expanding mask a bit\n",
    "    structuringElem = cv.getStructuringElement(\n",
    "        cv.MORPH_RECT, (dilation_size, dilation_size)\n",
    "    )\n",
    "    mask = cv.dilate(mask, structuringElem)\n",
    "\n",
    "    contours = cv.findContours(mask, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "    # Finding the largest segment\n",
    "    best_ind = 0\n",
    "    best_area = cv.contourArea(contours[0])\n",
    "    for i in range(1, len(contours)):\n",
    "        cur_area = cv.contourArea(contours[i])\n",
    "        if cur_area > best_area:\n",
    "            best_area = cur_area\n",
    "            best_ind = i\n",
    "\n",
    "    contours = contours[best_ind]\n",
    "    epsilon = 0.05 * cv.arcLength(contours, True)\n",
    "    contours = cv.approxPolyDP(contours, epsilon, True)\n",
    "    if len(contours) != 4:\n",
    "        # If no good rectangle found, leave the image unchanged\n",
    "        contours = np.array([[0, 0], [0, 223], [223, 223], [223, 0]])\n",
    "    else:\n",
    "        contours = np.array([point[0] for point in contours])\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(valset)\n",
    "batch = next(it)\n",
    "# batch = next(it)\n",
    "# batch = next(it)\n",
    "img, mask = batch\n",
    "output = model(img.unsqueeze(0).to(device)).cpu().squeeze()\n",
    "# print(output.size())\n",
    "cur_mask = output.detach().numpy()\n",
    "\n",
    "cur_mask = binarize_mask(cur_mask)\n",
    "# plt.imshow(cur_mask)\n",
    "corners = find_corners(cur_mask)\n",
    "print(cur_mask.shape)\n",
    "corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подзадача 2.\n",
    "\n",
    "Произвести трансформацию перспективы по найденным углам/контурам. Разумеется, трансформацию необходимо производить над исходным изображением, а не над масками.\n",
    "\n",
    "\n",
    "Для этого используются функции `cv2.getPerspectiveTransform` и\n",
    "`cv2.warpPerspective`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "print(corners.astype(np.float32))\n",
    "# perspTransfom = cv2.getPerspectiveTransform(corners.astype(np.float32), np.float32([[0,0], [0,223], [223,223], [223, 0]]))\n",
    "perspTransfom = cv.getPerspectiveTransform(\n",
    "    np.float32([[59, 125], [185, 130], [186, 177], [44, 170]]),\n",
    "    np.float32([[0, 0], [223, 0], [223, 223], [0, 223]]),\n",
    ")\n",
    "print(perspTransfom)\n",
    "result = cv.warpPerspective(\n",
    "    np.transpose(img.detach().numpy(), (1, 2, 0)), perspTransfom, (224, 224)\n",
    ")\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screenConv = np.float32([[0, 0], [223, 0], [223, 223], [0, 223]])\n",
    "\n",
    "for batch in valset:\n",
    "    img, mask = batch\n",
    "    output = model(img.unsqueeze(0).to(device)).cpu().squeeze()\n",
    "    output = output.detach().numpy()\n",
    "    cur_mask = binarize_mask(output)\n",
    "    img = np.transpose(img.detach().numpy(), (1, 2, 0))\n",
    "\n",
    "    cornersRes = find_corners(cur_mask)\n",
    "    perspTransfomRes = cv.getPerspectiveTransform(\n",
    "        cornersRes.astype(np.float32), screenConv\n",
    "    )\n",
    "    convertedRes = cv.warpPerspective(img, perspTransfomRes, (224, 224))\n",
    "\n",
    "    mask = np.transpose(mask.detach().numpy(), (1, 2, 0))\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    cornersOrig = find_corners(mask)\n",
    "    perspTransfomOrig = cv.getPerspectiveTransform(\n",
    "        cornersOrig.astype(np.float32), screenConv\n",
    "    )\n",
    "    convertedOrig = cv.warpPerspective(img, perspTransfomOrig, (224, 224))\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(30, 20))\n",
    "    ax[0, 0].imshow(img)\n",
    "    ax[0, 0].set_title(\"Original\")\n",
    "    ax[0, 1].imshow(mask[:, :, 0])\n",
    "    ax[0, 1].set_title(\"GT mask\")\n",
    "    ax[0, 2].imshow(convertedOrig)\n",
    "    ax[0, 2].set_title(\"Conversion from GT mask\")\n",
    "    ax[1, 0].imshow(output)\n",
    "    ax[1, 0].set_title(\"Network output\")\n",
    "    ax[1, 1].imshow(cur_mask)\n",
    "    ax[1, 1].set_title(\"Processed output\")\n",
    "    ax[1, 2].imshow(convertedRes)\n",
    "    ax[1, 2].set_title(\"Conversion from output mask\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Памятка для преподавателя\n",
    "<...>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
