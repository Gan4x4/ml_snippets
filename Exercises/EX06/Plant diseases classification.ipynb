{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyME4caYLjAunUNOZvms3j1E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ejujv2w8drWd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"1ADxyKZzymAa"},"source":["# Задание 4. Сверточная сеть для классификации заболеваний растений"]},{"cell_type":"markdown","metadata":{"id":"XsiJ3TbGymAb"},"source":["Используя созданные датасеты, обучите свёрточную нейронную сеть для определения заболевания растения. Используя фиксированную (по свёрточным слоям) архитектуру модели, посмотрите на качество обучения при различных размерах входных изображений и опишите причину наблюдаемой закономерности."]},{"cell_type":"markdown","metadata":{"id":"ciHOIh-jymAb"},"source":["## Памятка для преподавателя\n","\n","Цели задания:\n","\n","- Научить оборачивать собственные данные в совместимый с Pytorch ([torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) )\n","- Научить анализировать код. В создаваемом `Dataloader` параметра `shuffle=False`, все батчи одинаковы и модель не обучается.\n","- Продемонстрировать проблему с определением размерности входа Линейного слоя идущего за сверточными\n","\n","Особенности:\n","* <font color='red'>В студенческой версии блокнота у train_loader параметр shuffle = False. Студенты должны найти эту ошибку и исправить ее.  </font>\n","\n","* Так как мы не рассказываем в лекции про GlobalAveragePooling( [nn.AdaptiveAveragePooling](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html) ) то мы для каждого размера должны создавать новую модель. Что является антипаттерном.\n","\n","* Предположение что структура сети не должна зависеть от размеров входа не соответствует действительности. Соответственно у разных студентов будут разные лучшие размеры. Зависеть результат будет от того какую структуру модели студент выбрал.\n","\n","* При максимальном размере (500x500) изображения  большие модели не помещаются в память. Бороться с этим можно уменьшая batch_size\n","\n","* Низкая точность объясняется малым размером датасета и сложностью задачи.\n","* Время выполнения задания на GPU < 9 мин\n","* С учетом вышесказанного задание надо переделать\n"]},{"cell_type":"markdown","metadata":{"id":"qKmqPesOymAc"},"source":["Создание датасета из набора файлов\n","\n","Фотографии листьев растений находятся в трех архивах. Загрузим их:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKeQ6eZVymAc"},"outputs":[],"source":["!wget https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/ibeans/train.zip\n","!wget https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/ibeans/validation.zip\n","!wget https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/ibeans/test.zip\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"Z1PRfQLQymAd"},"source":["и разархивируем"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf1q6yzfymAd"},"outputs":[],"source":["!unzip train.zip\n","!unzip validation.zip\n","!unzip test.zip\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"RWYVCj11ymAe"},"source":["Каждый архив содержит папку с тремя подпапками:\n","\n","\n","*   angular_leaf_spot\n","*   bean_rust\n","*   healthy\n","\n","подпапки соответствует классу (название заболевания или здоровое растение)\n","\n","Для работы с данными в таком формате удобно использовать класс [torchvision.datasets.ImageFolder](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EFVudoINymAg"},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","\n","\n","val_dataset = ImageFolder(\"validation\")\n","train_dataset = ImageFolder(\"train\")\n","\n","print(\"Classes names\", val_dataset.classes)"]},{"cell_type":"markdown","metadata":{"id":"YY3-r9HxymAh"},"source":["Выведем одно изображение"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNyx6SuvymAi"},"outputs":[],"source":["img, cls_num = val_dataset[0]\n","print(f\"Size : {img.size} Class: {val_dataset.classes[cls_num]}\")  # pillow\n","display(img)"]},{"cell_type":"markdown","metadata":{"id":"ju-DbrtdymAj"},"source":["Создадим загрузчики\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGiw477EymAk"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"talbMkjqymAl"},"source":["Создайте сверточную сеть для классификации\n","\n","При этом:\n","* Ограничьте количество сверточных слоев пятью\n","* Используйте принцип: при увеличении количества фильтров в два раза, пространственные размеры карты признаков так же уменьшаются в два раза.\n","* Помните о том, что расход памяти связан не только с количеством параметров модели но и с размерами входа. Поэтому при подаче на вход изображений размером 500х500 можно получить ошибку связанную с нехваткой памяти."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kDLYOjBymAl"},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","\n","\n","class BeanCNN(nn.Module):\n","    def __init__(self, side_size=500):\n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1),\n","            MaxPool2d(2),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=1),\n","            MaxPool2d(2),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","        )\n","\n","        out = self.conv(torch.randn((3, side_size, side_size)).unsqueeze(0))\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(int(out.shape[1]), 512), nn.ReLU(), nn.Linear(512, 3)  # n_classes\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        scores = self.fc(x)\n","        return scores"]},{"cell_type":"markdown","metadata":{"id":"EV7MIwQJymAo"},"source":["\n","\n","\n","\n","\n","\n","P.s. Нам нужно менять размер изображения в ходе экспериментов, поэтому мы не стали передавать набор трансформаций в конструктор класса датасета. Будем устанавливать это свойство в начале каждого эксперимента."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsMSTA9OymAo"},"outputs":[],"source":["import torchvision.transforms as T\n","\n","\n","def get_transforms(side_size):\n","    # create set of transforms applied to the images\n","    return T.Compose(\n","        [\n","            T.Resize((side_size, side_size)),\n","            T.ToTensor(),\n","            T.Normalize(mean=[0.5183, 0.4845, 0.6570], std=[0.2111, 0.2227, 0.2291]),\n","        ]\n","    )"]},{"cell_type":"markdown","metadata":{"id":"DOSyJyXBymAp"},"source":["Обучите несколько вариантов модели, обрабатывающих входы различного размера. Допустимо использовать вспомогательные функции (validate, train) из первого задания. Для изменения размера изображений рекомендуется использовать механизм трансформаций PyTorch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDuKDU-yymAp"},"outputs":[],"source":["%%time\n","\n","from copy import deepcopy\n","\n","history = []\n","side_sizes = [500, 256, 128, 64, 32]\n","best_model = None\n","max_accuracy = 0\n","best_size = None\n","for side_size in side_sizes:\n","    # Change transform on both datasets\n","    transform = get_transforms(side_size)\n","    train_dataset.transform = transform\n","    val_dataset.transform = transform\n","\n","    model = BeanCNN(side_size=side_size)\n","    model.train()\n","    model.to(device)\n","\n","    pp = train(\n","        model, train_loader, val_loader, lr=0.003, epochs=8, title=str(side_size)\n","    )\n","    if max(pp.history_dict[\"Accuracy/val\"]) > max_accuracy:\n","        best_model = deepcopy(model)\n","        max_accuracy = max(pp.history_dict[\"Accuracy/val\"])\n","        best_size = side_size\n","\n","    history.append(pp)"]},{"cell_type":"markdown","metadata":{"id":"JtmhjEReymAq"},"source":["Сравните графики значений accuracy для разных размеров входных изображений:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5EcXzTcymAq"},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(10, 8))\n","ax.set_xlabel(\"img_sizes\")\n","ax.set_xticks(side_sizes)\n","ax.set_ylabel(\"best acc on test\")\n","ax.grid()\n","\n","for i, h in enumerate(history):\n","    x = h.history_dict[\"Accuracy/val\"]\n","    ax.plot(x, label=side_sizes[i])\n","ax.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-BiVH8UTymAr"},"source":["Проверьте результат на тестовом датасете"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1okaef8ymAs"},"outputs":[],"source":["test_dataset = ImageFolder(\"test\", transform=get_transforms(best_size))\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","accuracy = validate(best_model, test_loader, device)\n","\n","print(f\"Accuracy on TEST {accuracy:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"pLLV5BpdymAs"},"source":["Вывод:\n","\n","1. На совсем маленьких изображениях недостаточно информации для классификации. Пораженных участков попросту не видно.\n","\n","2. Разрешения 500 .. 128 в целом достаточно. При таких разрешениях точность зависит от выбранной архитектуры. Так как скорость обучения сильно зависит от объема входных данных, целесообразно уменьшать картинку в 2-3 раза.\n","3. Для корректной работы алгоритма стохастического градиентного спуска пришлось изменить значения параметра shuffle с False на True, чтобы батчи на разных эпохах различались\n"]},{"cell_type":"markdown","metadata":{"id":"OEkkpXiTymAt"},"source":["## Формат результата"]},{"cell_type":"markdown","metadata":{"id":"P8sGzJJJymAt"},"source":["Результатом является показание точности сети при различных размерах входных изображений.\n","\n","Например:\n","\n","* Размер изображения 32х32 точность 0.6\n","\n","* Размер изображения 64х64 точность 0.7\n","\n","* Размер изображения 500х500 точность 0.57\n"]}]}