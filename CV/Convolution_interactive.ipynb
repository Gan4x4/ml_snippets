{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+g0wp1upFsA1UsXVprOLF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RkcxtGsBOvSg"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"RmBLeOcAVd-S"},"source":["Как мы успели рассмотреть выше, свёрточный слой нейросети осуществляет преобразование некоторого набора входных карт признаков в новый определенный набор выходных карт признаков. Выбор параметров ядра свёртки, числа входных и выходных каналов, величина и тип расширения (padding) полностью определяет \"геометрию\" данного преобразования.\n","\n","На практике, при написании собственных нейронных сетей со свёрточными слоями, мы хотим последовательно пропускать изображение через несколько свёрточных слоёв, передавая полученные на выходе одного свёрточного слоя карты признаков на вход другому. "]},{"cell_type":"markdown","metadata":{"id":"Kc2QWqFrVd-T"},"source":["Как уже отмечалось выше, свёрточные слои могут принимать на вход карты признаков произвольной ширины и высоты (главное, чтобы ширина и высота карты признаков после расширения (padding) была не меньше размера ядра свёртки) — таким образом, при последовательном соединении свёрточных слоёв остаётся обеспечить согласование числа карт признаков: количество карт признаков на выходе слоя должно равняться числу входных карт признаков следующего после него слоя.\n","\n","При построении некоторых архитектур CNN (например, для архитектуры [UNet](https://arxiv.org/abs/1505.04597)) важно явно контролировать пространственные размеры всех используемых карт признаков. Чтобы разобраться, как происходит преобразование размеров карт признаков, обратимся к описанию класса [`torch.nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d) из библиотеки PyTorch."]},{"cell_type":"markdown","metadata":{"id":"T-p0s4h4Vd-T"},"source":["`torch.nn.Conv2d` принимает на вход тензор вида $(N, C_{in}, H, W)$, где $N$ нулевом измерении (как всегда) соответствует размерности батча, $C_{in}$ соответствует числу входных карт признаков, а $H$ и $W$ задают пространственные размеры входных карт признаков. На выходе мы получаем тензор вида $(N, C_{out}, H_{out}, W_{out})$, где количество выходных карт признаков $C_{out}$ задаётся при создании экземпляра класса `torch.nn.Conv2d`, а пространственные измерения выходных карт признаков $H_{out}$ и $W_{out}$ вычисляются на основе параметров ядра свёртки и размеров $H$ и $W$ входных карт признаков по формулам:\n","\n","$$ H_{out} = \\lfloor \\frac{H + 2 \\times \\text{padding_h} - \\text{dilation_h} \\times (\\text{kernel_size_h} - 1) -1}{\\text{stride_h}}  + 1 \\rfloor ,$$\n","$$ W_{out} = \\lfloor \\frac{W + 2 \\times \\text{padding_w} - \\text{dilation_w} \\times (\\text{kernel_size_w} - 1) -1}{\\text{stride_w}}  + 1 \\rfloor ,$$\n","\n","где\n","* `kernel_size_h` и `kernel_size_w` &mdash; количество элементов ядра свёртки по ширине и высоте;\n","* `padding_h` и `padding_w` &mdash;  параметры расширения выходной карты признаков нулями по ширине и высоте ;\n","* `stride_h` и `stride_w` &mdash; сдвиг свёртки по ширине и высоте, будет подробно рассмотрено ниже;\n","* `dilation_h` и `dilation_w` &mdash; расстояние между ядерными элементами (позволяет рассматривать только те пространственные элементы карты признаков, координаты которых кратны величинам сдвига по ширине и высоте; по умолчанию данная величина равна $1$ и в свёртке принимает участие вся карта признаков); С dilated convolutions мы подробнее познакомимся при рассмотрении CNN архитектур, используемых для семантической сегментации."]},{"cell_type":"markdown","metadata":{"id":"HCOSf6g1Vd-U"},"source":["Интерактивный пример преобразования набора входных карт признаков свёрточным слоем:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XE0lVvXBVd-U"},"outputs":[],"source":["# @title \\<code block for conv2d visualization purposes\\>\n","\n","from torch import Tensor\n","\n","from ipywidgets import interactive\n","import ipywidgets as widgets\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","def plot_featuremaps(\n","    featuremap_tensor: Tensor, title: str = \"\", v_max: int = None\n",") -> None:\n","    n_maps, h, w = featuremap_tensor.shape[1:]\n","    fig, ax = plt.subplots(\n","        ncols=n_maps, figsize=(5 * n_maps, 5), sharex=False, sharey=False\n","    )\n","\n","    featuremap_tensor = featuremap_tensor.detach()\n","    if n_maps > 1:\n","        for id_ax in range(n_maps):\n","            sns.heatmap(\n","                featuremap_tensor[0][id_ax],\n","                ax=ax[id_ax],\n","                annot=True,\n","                fmt=\"0.00f\",\n","                cbar=False,\n","                vmin=0,\n","                vmax=v_max,\n","                linewidths=1,\n","            )\n","    else:\n","        sns.heatmap(\n","            featuremap_tensor[0][0],\n","            ax=ax,\n","            annot=True,\n","            fmt=\"0.00f\",\n","            cbar=False,\n","            vmin=0,\n","            vmax=v_max,\n","            linewidths=1,\n","        )\n","\n","    fig.suptitle(title)\n","    plt.show()\n","\n","\n","def conv2d_example(\n","    h_in: int = 8,\n","    w_in: int = 8,\n","    in_channels: int = 2,\n","    out_channels: int = 1,\n","    kernel_size_h: int = 3,\n","    kernel_size_w: int = 3,\n","    padding_h: int = 0,\n","    padding_w: int = 0,\n","    stride_h: int = 1,\n","    stride_w: int = 1,\n","    dilation_h: int = 1,\n","    dilation_w: int = 1,\n",") -> None:\n","    \"\"\"\n","    This function generates an example of the input\n","    feature maps tensor, passes it to a two-dimensional\n","    convolution with the specified parameters and\n","    unit weights, and then returns the resulting\n","    feature maps output tensor.\n","    \"\"\"\n","\n","    dummy_input = torch.tensor(\n","        [[list(range(h_in))] * w_in] * in_channels, dtype=torch.float\n","    ).unsqueeze(\n","        0\n","    )  # Let's create an example input tensor like $(1, C_{in}, H. W)$\n","\n","    conv_layer = nn.Conv2d(\n","        in_channels=in_channels,\n","        out_channels=out_channels,\n","        kernel_size=(kernel_size_h, kernel_size_w),\n","        padding=(padding_h, padding_w),\n","        stride=(stride_h, stride_w),\n","        dilation=(dilation_h, dilation_w),\n","        bias=False,\n","    )  # Creating an instance of the 2D convolution class with the given parameters.\n","\n","    conv_layer.weight = nn.Parameter(\n","        torch.ones_like(conv_layer.weight)\n","    )  # Replace random weights to ones\n","    output = conv_layer(dummy_input)\n","    print(\"\\n\\nExample of input feature maps:\")\n","    plot_featuremaps(\n","        dummy_input, f\"input featuremap tensor\\nshape = {dummy_input.shape}\", v_max=h_in\n","    )\n","\n","    print(f\"\\n\\nconv kernel shape is {conv_layer.weight.shape}\\n\\n\")\n","\n","    print(\"Example of output feature maps:\")\n","    plot_featuremaps(output, f\"output featuremap tensor\\nshape = {output.shape}\")\n","\n","\n","conv2d_example_interactive = interactive(\n","    conv2d_example,\n","    h_in=widgets.IntSlider(min=8, max=32, step=1, value=8),\n","    w_in=widgets.IntSlider(min=8, max=32, step=1, value=8),\n","    in_channels=widgets.IntSlider(min=1, max=4, step=1, value=3),\n","    out_channels=widgets.IntSlider(min=1, max=4, step=1, value=2),\n","    kernel_size_h=widgets.IntSlider(min=1, max=8, step=1, value=3),\n","    kernel_size_w=widgets.IntSlider(min=1, max=8, step=1, value=3),\n","    padding_h=widgets.IntSlider(min=0, max=8, step=1, value=0),\n","    padding_w=widgets.IntSlider(min=0, max=8, step=1, value=0),\n","    stride_h=widgets.IntSlider(min=1, max=8, step=1, value=1),\n","    stride_w=widgets.IntSlider(min=1, max=8, step=1, value=1),\n","    dilation_h=widgets.IntSlider(min=1, max=8, step=1, value=1),\n","    dilation_w=widgets.IntSlider(min=1, max=8, step=1, value=1),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpCgAcTYVd-W","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f718958647bb4b9092041cb228143f0e","637c8c00046747c2b4b8ca362c38781c","3ae38c9aeddd4939a7d61465d3c0bd44","fb437dd8bd6a4f0c992b649b0c896e9e","805d152103234b9a8ec2fa6a65439b76","6c84d3e41e2142818a9dbf7b2349c26a","82704c3a52044ee38b3a403c7001a254","9f518e67cc3842828cc78ab77b61bafe","cc43adcc20b843b89b86dc1e531e6ab5","6991ae39b3cd4086a9b060d1838d853e","7d2e47b1b9de4881bbf05d81e71397fc","f3d4174e4b0c46c7895232972c85a005","b2bdee20641741e5b39e93bf4037ceb2","63139bf0c57342008d0173c178cc086d","27a50e7087d74cae9a99a622a05dd789","74abc7c6c36246c6a6bab6543cb0a627","9e47f820bb9f431bb3518fb8e0f3b141","00681c66861e4110b38bac793517ebc1","a58aeb9933da4b958b76942f3e486d61","d5709b06079a4471adb8fdd35239a040","c3f1ecbea7fb403382daa2f9f90082a1","d4770a87d5a34fbca277d06ebaae74f9","34027485e2914a85bf582f93cdb6cea2","d8bf99f248f74aadab081a21a038173d","ddd33924735d404dbf950a0911f97d8b","63be6e5bd0394604a290bd04f5c6abbf","42e6a48bff464efa9cd655dd2e397c65","d65b352415644b41bb31affbc76e8af1","a56c35de04ac4806a833ab2d230dfa4b","878b267030384d4c947b51421690c0d8","f44e86dd5a4c400ca2f0ad2c9a373c30","54e0a45db9134367a6c3e837588953f2","108208554d2e4eb8861c3fd18c23c311","e0d38f7bffdc4063ae68279e48f2b873","0eb631ad80ec406cada6fbcf00d7d478","22da7eb960434adf9fbe10f0700bf560","c370c8f3aa6c4ab994f87cfca6a8ebb9","b824309b3aee42d1af17c5c6f6e1e63a","7a62b2b94807435db1a2027ff559aff8","76994f1908af4837aa1725f637c514c1"]},"executionInfo":{"status":"ok","timestamp":1679503773618,"user_tz":-180,"elapsed":2891,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"fca08603-3ba9-4aed-e0c4-4f519179f026"},"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=8, description='h_in', max=32, min=8), IntSlider(value=8, description='w…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f718958647bb4b9092041cb228143f0e"}},"metadata":{}}],"source":["display(conv2d_example_interactive)"]},{"cell_type":"markdown","metadata":{"id":"Iz06-KY3Vd-t"},"source":["Мы успели довольно подробно рассмотреть свёрточный слой и заметить большое количество его сходств с полносвязным слоем (перцептроном). Теперь давайте попробуем сравнить эти два слоя по требуемому количеству параметров и операций умножения.  \n","\n","В первую очередь давайте определимся с размерами входного и получаемого тензоров. Пусть на вход передаётся $C_{in}\\times H_{in}\\times W_{in}$. На выходе пусть будет $K$ нейронов для полносвязного слоя и $C_{out}\\times H_{out} \\times W_{out}$ для свёрточного слоя (фильтр имеет размер $C_{in} \\times F_1 \\times F_2$). $F_1$ и $F_2$ - размер ядра свёртки по высоте и ширине, соответственно.\n","\n","Для простоты расчётов давайте примем, что шаг фильтра равен $1$ как по горизонтали, так и по вертикали. В таком случае, $H_{out} = H_{in} - F_1 + 1$, а $W_{out} = W_{in} - F_2 + 1$."]},{"cell_type":"markdown","metadata":{"id":"d_wYzy6OVd-t"},"source":["##### Количество параметров:  \n","***Полносвязный слой:***  \n","Данный слой требует по параметру (весу) для всех связей между входными и выходными нейронами, то есть $C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K$. Помимо этого, каждый из выходных нейронов имеет свободный член, общее количество которых $K$. Итого, количество обучаемых параметров: $(C_{in} \\cdot H_{in} \\cdot W_{in} + 1) \\cdot K$.\n","\n","***Свёрточный слой:***  \n","Для свёрточного слоя параметры связаны лишь с ядрами свёртки: внутри каждого ядра находятся $C_{in} \\cdot F_1 \\cdot F_2$ параметров, общее их количество &mdash; $C_{out}$. Помимо этого, каждое из ядер имеет свой собственный свободный член, поэтому общее количество обучаемых параметров: $(C_{in} \\cdot F_1 \\cdot F_2 + 1) \\cdot C_{out}$.\n","\n","***Сравнение количества параметров:***  \n","Поскольку количество свободных членов мало относительно количества весов, мы опустим их в этих расчётах. \n","$$Comp_{param} = \\frac{C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K}{C_{in} \\cdot F_1 \\cdot F_2 \\cdot C_{out}} = \\frac{H_{in} \\cdot W_{in} \\cdot K}{F_1 \\cdot F_2 \\cdot C_{out}}.$$ "]},{"cell_type":"markdown","metadata":{"id":"Di-zVBIzVd-v"},"source":["##### Количество умножений: \n","***Полносвязный слой:***  \n","В данном слое каждый вес используется лишь один раз, в результате общее количество умножений: $$C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K$$.  \n","\n","***Свёрточный слой:***\n","Заметим, что, в отличие от перцептрона, свёрточная нейронная сеть использует каждый вес несколько раз (при подсчёте каждого из элементов карты активации). Размер карты активаций: $H_{out} \\times W_{out}$. В итоге оказывается, что количество операций умножения равно: $$C_{in} \\cdot F_1 \\cdot F_2 \\cdot C_{out} \\cdot H_{out} \\cdot W_{out}$$.\n","\n","***Сравнение количества умножений:***\n","$$Comp_{mult} = \\frac{C_{in} \\cdot H_{in} \\cdot W_{in} \\cdot K}{C_{in} \\cdot F_1 \\cdot F_2 \\cdot C_{out} \\cdot H_{out} \\cdot W_{out}} = \\frac{H_{in} \\cdot W_{in} \\cdot K}{F_1 \\cdot F_2 \\cdot C_{out} \\cdot H_{out} \\cdot W_{out}} = \\frac{Comp_{param}}{H_{out} \\cdot W_{out}}.$$"]}]}