{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHgnWpsxYcQySw1poy5WFA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3KJO00JD4oKD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"lC9K5qNOVd-E"},"source":["<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_filter_forward_pass.png\" width=\"200\">"]},{"cell_type":"markdown","metadata":{"id":"PsBPyYbMVd97"},"source":["## Основные параметры свёртки"]},{"cell_type":"markdown","metadata":{"id":"L9-8NiaIVd98"},"source":["Как уже упоминалось ранее, по сути операция свёртки представляет из себя вычисление взвешенной суммы со свободным членом, что довольно сильно напоминает линейный слой с тем лишь отличием, что последний применяется ко всем данным, а не к их части. Тем не менее, подобно линейному слою, операцию свёртки можно встроить в нейросеть и, путём градиентного спуска, подбирать параметры свёртки. "]},{"cell_type":"markdown","metadata":{"id":"_I_Yrv6qVd9-"},"source":["<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/img_and_convolution_filter.png\" width=\"300\">"]},{"cell_type":"markdown","metadata":{"id":"QLZ5EtLvVd-I"},"source":["В свёрточном слое указаны необходимые для создания ядра свёртки параметры: количество каналов во входном представлении `in_channels` и размер ядра свёртки `kernel_size`. Также в нём необходимо указывать количество используемых фильтров `out_channels`. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6dcJG-MVd-I"},"outputs":[],"source":["conv = torch.nn.Conv2d(\n","    in_channels=3,  # Number of input channels (3 for RGB images)\n","    out_channels=5,  # Number of filters/output channels\n","    kernel_size=3,\n",")\n","\n","img = torch.randn(\n","    (1, 3, 100, 100)\n",")  # 1-batch size, 3-num of channels, (100,100)-img size\n","print(f\"img shape: {img.shape}\")\n","\n","out = conv(img)\n","print(f\"out shape: {out.shape}\")  # [1, 5, 98, 98]"]},{"cell_type":"markdown","metadata":{"id":"y9vivEmBVd94"},"source":["К примеру, на GIF ниже можно увидеть, как фильтр размером $3\\times3$ применяется к одноканальному изображению размером $5\\times5$. Шаблон имеет форму x-образного креста. В правой части можно увидеть, насколько фрагмент изображения под фильтром совпадает с шаблоном внутри фильтра.\n","\n","<img src =\"https://edunet.kea.su/repo/EduNet-content/L06/out/convolution_with_filter.gif\" width=\"300\">"]},{"cell_type":"markdown","metadata":{"id":"Ufap7vNgVd-D"},"source":["Результатом свертки входного тензора с одним фильтром будет карта признаков с глубиной 1, вне зависимости от количества каналов входного тензора.\n","\n","Во время прямого прохода фильтр перемещается по ширине и высоте входного тензора и вычисляются скалярные произведения между значениями фильтра и соответствующими значениями входного тензора. Так формируется двумерная карта признаков, которая содержит результат применения данного фильтра к каждой из областей входного тензора.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7QNjTXlVd-F"},"outputs":[],"source":["img = torch.randn((3, 8, 8))  # 3-num of channels, (8,8)-img size\n","kernel = torch.randn((3, 3, 3))  # 3-num of filters, (3,3)-kernel size\n","\n","result = torch.zeros(6, 6)  # 8 - 3 + 1 = 6\n","\n","for i in range(result.shape[0]):\n","    for j in range(result.shape[1]):\n","        segment = img[:, i : i + kernel.shape[0], j : j + kernel.shape[1]]\n","        result[i, j] = torch.sum(segment * kernel)\n","\n","print(f\"img shape: {img.shape}\")\n","print(f\"kernel shape: {kernel.shape}\")\n","print(f\"result shape: {result.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"rD2yDuhnVd9_"},"source":["Реализуем операцию свертки с помощью линейного слоя:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBYeRAliVd9_"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","local_linear = nn.Linear(9, 1, bias=False)  # 9 = 3 * 3 (weights shape: (3,3))\n","\n","# fmt: off\n","img = torch.Tensor([[1, 1, 1, 0, 0],\n","                    [0, 1, 1, 1, 0],\n","                    [0, 0, 1, 1, 1],\n","                    [0, 0, 1, 1, 0],\n","                    [0, 1, 1, 0, 0]])\n","# kernel weights\n","weights = torch.Tensor([[1, 0, 1],\n","                       [0, 1, 0],\n","                       [1, 0, 1]])\n","# fmt: on\n","\n","local_linear.weight = nn.Parameter(weights.reshape(-1))  # set weights\n","\n","result = torch.zeros((3, 3))  # img - kernel + 1 (5 - 3 + 1 = 3)\n","\n","for i in range(0, result.shape[0]):\n","    for j in range(0, result.shape[1]):\n","        segment = img[i : i + weights.shape[0], j : j + weights.shape[1]].reshape(-1)\n","        result[i, j] = local_linear(segment)\n","\n","print(f\"img shape: {img.shape}\")\n","print(f\"weights shape: {weights.shape}\")\n","print(f\"result shape: {result.shape}\")\n","print(f\"result:\\n{result}\")"]},{"cell_type":"markdown","metadata":{"id":"ldp6KGnOVd-P"},"source":["```\n","\"VALID\" = без паддинга:\n","\n","   inputs:         1  2  3  4  5  6  7  8  9  10 11 (12 13)\n","                  |________________|                dropped\n","                                 |_________________|\n","\"SAME\" = с паддингом нулями:\n","\n","               pad|                                      |pad\n","   inputs:      0 |1  2  3  4  5  6  7  8  9  10 11 12 13|0  0\n","               |________________|\n","                              |_________________|\n","                                             |________________|\n","```\n","\n","Ниже можно увидеть пример обработки RGB изображения с same padding (с использованием 0):"]}]}