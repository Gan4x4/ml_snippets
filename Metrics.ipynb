{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7Z0aXln+jijK7NvBpAL0o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Adopted from here: https://colab.research.google.com/github/vitalfedorov/ML_Notes/blob/master/Metrics.ipynb#scrollTo=lIff76-PbWHS"],"metadata":{"id":"W8KxfHUcKctQ"}},{"cell_type":"markdown","source":["<table><tr><td>\n","<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png\" width=\"400\" display=\"inline\">\n","</td><td>\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Sensitivity_and_specificity_1.01.svg/341px-Sensitivity_and_specificity_1.01.svg.png\" width=\"400\" display=\"inline\">\n","</td></tr></table>"],"metadata":{"id":"1G1liLCRMRuF"}},{"cell_type":"markdown","source":["### Precision or Positive Predictive Value (PPV)\n","Precision is a valid choice of evaluation metric when we want to be very sure of our prediction. For example: If we are building a system to predict if we should decrease the credit limit on a particular account, we want to be very sure about our prediction or it may result in customer dissatisfaction.\n","\n","\\begin{equation*}\n","PPV = \\frac{TP}{TP + FP}\n","\\end{equation*}\n","\n","With increse of FP, PPV will decline. If FP=0, PPV=1"],"metadata":{"id":"OI4nvfzNKVwn"}},{"cell_type":"markdown","source":["### Recall (Sensitivity) or True Positive Rate (TPR)\n","Recall is a valid choice of evaluation metric when we want to capture as many positives as possible. For example: If we are building a system to predict if a person has cancer or not, we want to capture the disease even if we are not very sure.  \n","\n","\\begin{equation*}\n","TRP = \\frac{TP}{TP + FN}\n","\\end{equation*}\n","\n","With increase of FN, TRP will decline. If FN=0, TRP=1. We don't care about FP."],"metadata":{"id":"KHCYFTeRLiEz"}},{"cell_type":"markdown","source":["### Specificity, selectivity or true negative rate (TNR)\n","\n","\\begin{equation*}\n"," TNR = \\frac{TN }{ TN + FP}\n","\\end{equation*}"],"metadata":{"id":"FOL2nFR2O9ui"}},{"cell_type":"markdown","source":["\n","### Accuracy (ACC)\n","Accuracy is a valid choice of evaluation for classification problems which are well balanced and not skewed or No class imbalance.\n","\n","\\begin{equation*}\n","PPV = \\frac{TP + TN}{TP + TN + FP + FN}\n","\\end{equation*}\n","\n","Accuracy simply means the percentage of correct observations.\n","### F1 score\n","Itâ€™s the harmonic mean between precision and recall.\n","\\begin{equation*}\n","F_1 = 2*\\frac{Precision * Recall}{Precision + Recall}\n","\\end{equation*}\n","\n","### F1 score with Beta\n","When choosing beta in your F-beta score the more you care about recall over precision the higher beta you should choose.\n","\\begin{equation*}\n","F_1 = (1+\\beta^2)*\\frac{Precision * Recall}{(\\beta^2*Precision) + Recall}\n","\\end{equation*}"],"metadata":{"id":"3WXVt4Y7KTYq"}},{"cell_type":"markdown","source":["#Balanced Accuracy\n","\n","https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score\n","\n","$ \\texttt{balanced-accuracy} = \\frac{1}{2}\\left( \\frac{TP}{TP + FN} + \\frac{TN}{TN + FP}\\right ) $"],"metadata":{"id":"nU-t0R3WLOnz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cVWfUV0aJ1Bo"},"outputs":[],"source":[]}]}