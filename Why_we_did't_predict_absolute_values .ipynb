{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно по схеме не предсказываются абсолютные значения смещений. Почему вместо того что бы в понятной регрессионной задаче не предсказать 4 числа предсказываются  коеффициенты, с которыми затем происходят неочевидные преобразования?\n",
    "\n",
    "Что бы ответить на этот вопрос вспомним про нормализацию данных. Мы нормализуем входные данные, чаще всего так что бы среднее заначение было 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.randn((512,100)) # Fake normalized data\n",
    "plt.hist(x.mean(dim=0),bins=10)\n",
    "plt.show()\n",
    "print(f\"Mean: {x.mean().item():.2f} Variance: {x.var().item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Кроме того мы определенным образом инициализируем веса и добавляем слои ализации что бы распределение входов очередного слоя (они же выходы предидущего) более-менее сохранялось.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(100,50), # weights randomly sampled from some random distribution\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.Linear(50,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса инициализированны равномерно расперделены вокруг нуля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = net[0].weight.data.numpy()\n",
    "plt.hist(weights.flatten(),bins=20)\n",
    "plt.show()\n",
    "print(weights.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И на выходе последнего слоя будет та же ситуация: необученная сеть будет чаще всего предсказывать около нулевые значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(x)\n",
    "plt.hist(out.detach().numpy(),bins=20)\n",
    "plt.show()\n",
    "print(f\"Mean: {out.mean().item():.2f} Variance: {out.var().item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы будем пытаться предсказывать большие по модулю значения, например абсолютные координаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.randint(0,224,(512,1)) # fake coordinate in range [0 .. 255]\n",
    "print(targets[:10].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То получим огромную ошибку, которая повлечет большое обновление весов приведет к нестабильному обучению, большим абсолютным значениям весов и.т.п."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, targets)\n",
    "print(\"Loss\",loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы стандартизуем координаты(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = targets.float().mean()\n",
    "std = targets.float().std()\n",
    "\n",
    "transformed_targets = (targets - mean)/std\n",
    "print(transformed_targets.flatten()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То получим ошибку на 4 порядка меньше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(out, transformed_targets)\n",
    "print(\"Loss\",loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фактически теперь мы предсказываем смещение от среднего значения. Что бы его затем использовать надо его денормализовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_out = out*std + mean\n",
    "print(real_out.int().flatten()[:10]) # values like a coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда такую постобработку удобно включить в модель, что бы она учитывалась при подсчете loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.linspace(-5,5)\n",
    "y = 1/(1 + np.exp(-x))\n",
    "plt.plot(x,y)\n",
    "plt.axvline(0,color = \"black\", alpha = 0.4)\n",
    "plt.title(\"Sigmoid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort numpy as np\n",
    "x = np.linspace(-2,2)\n",
    "y = np.exp(x)\n",
    "plt.plot(x,y)\n",
    "plt.axvline(0,color = \"black\", alpha = 0.4)\n",
    "plt.title(\"Exp\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
