{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/github.com/Gan4x4/ml_snippets/blob/main/Training/Lightning.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "aRsUXgDyWyxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обычный цикл обучения в Torch\n",
        "При работе с Pytorch базовый pipeline обучения выглядит примерно так"
      ],
      "metadata": {
        "id": "1AzwsFBHj1Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных"
      ],
      "metadata": {
        "id": "ghuA6uxNkPbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.13), (0.3))]\n",
        ")\n",
        "\n",
        "mnist = datasets.MNIST(root=\"./\", train=True, download=True, transform=transform)\n",
        "\n",
        "# Reduce size of dataset to speedup training\n",
        "train_set, val_set, _ = torch.utils.data.random_split(mnist, [10000, 3000, 47000])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True , num_workers=2)"
      ],
      "metadata": {
        "id": "FpMUerKNk1xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание модели"
      ],
      "metadata": {
        "id": "5aZ0NP8bkSBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.core = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,10)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.core(x)"
      ],
      "metadata": {
        "id": "_1BAfbF4lKTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()"
      ],
      "metadata": {
        "id": "t35IC1LViZIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Код для валидации"
      ],
      "metadata": {
        "id": "PIclHzagBjCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "@torch.inference_mode()  # this annotation disable grad computation\n",
        "def validate(model, test_loader,device):\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in test_loader:\n",
        "        pred = model(imgs.to(device))\n",
        "        total += labels.size(0)\n",
        "        _, predicted = torch.max(pred.data, 1) #shape = batch_size, class_count\n",
        "        correct_predictions =  (predicted.cpu() == labels.cpu()).sum()\n",
        "        correct += correct_predictions.sum().item()\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "ZW_Rh5-OBe3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение (train loop)"
      ],
      "metadata": {
        "id": "_wzoMn0hkXXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Q1vOuQymAI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "# managing device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = SimpleModel()\n",
        "model.to(device)\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Weight update\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in train_loader:\n",
        "    # Processing one batch\n",
        "    imgs, labels = batch\n",
        "    optimizer.zero_grad()\n",
        "    out = model(imgs)\n",
        "    loss = criterion(out, labels.to(device))\n",
        "    loss.backward()\n",
        "\n",
        "    # Calclulate metrics: TODO\n",
        "    # Save metrics to logs:  TODO\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  # Validation step\n",
        "  print(f\"Epoch {epoch} accuracy: {validate(model,val_loader,device):.2f}\")\n",
        "  # Save checkpoint: TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "OauBrQB6kbea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.13), (0.3))]\n",
        ")\n",
        "testset = datasets.MNIST(root=\"./\", train=False, download=True, transform = test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False)\n",
        "accuracy = validate(model, test_loader, device)\n",
        "\n",
        "print(f\"Accuracy on TEST {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "iDxP0BEOi29H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lightning\n",
        "\n",
        "При обучении моделей в pytorch нам часто приходиться переписовать цикл обучения (train loop) это дублирование кода, которое нарушает принцип [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself).\n",
        "\n",
        "Кроме того нам нужно следить за процессом обучения модели, например если loss взрываться или выходит на плато как правило есть смысл остановить обучение. Чтобы контролировать этот процесс приходиться добавлять дополнительный код для вывода и/или логгирования метрик.\n",
        "\n",
        "При проведении реальных экспериментов логирование результатов станет необходимым. Фреймворк ([Lightning](https://lightning.ai/)) облегчает написание tain loop, логирование результатов, и выполняет за нас ряд других задач."
      ],
      "metadata": {
        "id": "Ls417pKb1ZyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "7a9FInFA4lEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train loop в Lightning\n",
        "Базовая задача которую решает Lightning это реализация train loop.\n",
        "\n",
        "Типичный цикл обучения разбит на фрагменты каждый из которых помещен в соответствующий метод класса LightningModule. Посмотрим на послдовательность их вызовов:"
      ],
      "metadata": {
        "id": "QNnxNZpcYXCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB69ND0f5LPZ"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "class LitDemo(L.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        print(\"configure_optimizers\")\n",
        "        #return optimizer\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        print(\"on_train_epoch_start\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        #print(\"training_step\")\n",
        "        pass\n",
        "        #return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        # called only if validation_step implemented\n",
        "        print(\"on_validation_epoch_start\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        #print(\"validation_step\")\n",
        "        pass\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(\"on_validation_epoch_end\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        print(\"on_train_epoch_end\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что бы воспользоваться таким модулем надо передать его в объект класса Trainer"
      ],
      "metadata": {
        "id": "tkoD-wDq526t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#L.seed_everything(42)\n",
        "lit_model = LitDemo()\n",
        "trainer = L.Trainer(max_epochs=1)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "85jZqswI6QBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, один цикл валидации запускается до до начала эпохи обучения, а затем повторяеттся внутри каждой эпохи.\n",
        "\n",
        "Отключить первый вызов валидации можно инициализировав Trainer c параметром num_sanity_val_steps=0"
      ],
      "metadata": {
        "id": "8jrMrIx485KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitDemo()\n",
        "trainer = L.Trainer(max_epochs=1,\n",
        "                    num_sanity_val_steps=0 # disable vlidation before first epoch\n",
        "                    )\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "gml_guMK9iQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Перепишем цикл обучения из на Lightning.\n"
      ],
      "metadata": {
        "id": "GuXMOVaL9xKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель мы можем не менять, достаточно сохранить на нее ссылку при инициализации.\n",
        "Также инициализировать оптимизатор и перенести чать кода в train_step"
      ],
      "metadata": {
        "id": "oA5DSIHO-csG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitMinimal(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01,momentum =0.9)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "awWISGWJ-79v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При создании оптимизатора мы передаем ему не параметры модели, а параметры всего модуля, поэтом не важно как будет называться свойство содержащее ссылку на модель.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOqGoXGV_Xom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitMinimal(model)\n",
        "trainer = L.Trainer(max_epochs=1)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "Sy-A5FDRAItI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код выше минимально необходимый для обучения, он незначительно упрощает создание train_loop\n",
        "\n",
        "При этом фреймворк самостоятельно:\n",
        "- обновляет веса модели\n",
        "- сохраняет checkpoints на диск\n",
        "\n",
        " в нем нет методов для оценки точности или вывода графика loss."
      ],
      "metadata": {
        "id": "aKML6apdASx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torchmetrics\n",
        "\n",
        "Для выисления метрик установим пакет [torchmetrics](https://torchmetrics.readthedocs.io/en/stable/)"
      ],
      "metadata": {
        "id": "CmftzNO3BC7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "sXKpoPyAjyWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики это объекты"
      ],
      "metadata": {
        "id": "nZf54vbRyWhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "# Basic usage\n",
        "preds = torch.tensor([1.,2.,3.])\n",
        "labels = torch.tensor([1,2,9])\n",
        "print(\"Accuracy\",accuracy_metric(preds,labels))\n"
      ],
      "metadata": {
        "id": "UFsyT76Syjcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Они могут накапливать данные а потом вычислять заначение метрики."
      ],
      "metadata": {
        "id": "sf5CTFXtzxQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy\",accuracy_metric.compute()) # old values stored in memory"
      ],
      "metadata": {
        "id": "AFP8pqw20fv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если они не нужны следует их очистить"
      ],
      "metadata": {
        "id": "lfmK0k4y0nUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric.reset() # lear old values\n",
        "print(\"Accuracy\",accuracy_metric.compute())"
      ],
      "metadata": {
        "id": "sh5f_QWI0slf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обычно нужно делать это в конце эпохи, так как многие метрики считаются за эпоху"
      ],
      "metadata": {
        "id": "Vptk7cIg_qiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  preds = torch.randint(0,10,(256,10)).float() # batch predictions\n",
        "  labels = torch.randint(0,10,(256,)) # batch labels\n",
        "  accuracy_metric.update(preds,labels)\n",
        "\n",
        "print(\"Accuracy\",accuracy_metric.compute())\n",
        "accuracy_metric.reset()"
      ],
      "metadata": {
        "id": "G2pdwb5gz0c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Логиррование в Lightning\n",
        "\n",
        "Добавим подсчет метрики в lightning модуль.\n",
        "\n",
        "\n",
        "Будем добавлять значения в метрику при обработке каждого batch.\n",
        "\n",
        "А считать значение метрики будем в конце каждой эпохи обучения.\n",
        "\n"
      ],
      "metadata": {
        "id": "yD8vZ1OE5ROW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метод log\n",
        "Для сохранения значений (метрик и любых других) в lightning модуле реализован метод `log`. Используем его так же для согранения loss на каждом batch.\n",
        "\n",
        "Что бы последнее значение отображалось в progress bar установим параметр `prog_bar = True`"
      ],
      "metadata": {
        "id": "yIEQFZjgBCB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitWithMetric(LitMinimal):\n",
        "  def __init__(self, model):\n",
        "      super().__init__(model)\n",
        "      self.metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      out = self.model(x)\n",
        "      loss = self.criterion(out, y)\n",
        "      self.metric.update(out, y)\n",
        "      self.log(\"loss\", loss,prog_bar = True)\n",
        "      return loss\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "      self.log(\"accuracy/train\", self.metric.compute(),prog_bar = True)\n",
        "      self.metric.reset()\n"
      ],
      "metadata": {
        "id": "obLP1mVs5hWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()\n",
        "lit_model = LitWithMetric(model)\n",
        "trainer = L.Trainer(max_epochs=3) # def on_validation_epoch_start(self):\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "K6p9Hg0s6rkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Просмотр логов"
      ],
      "metadata": {
        "id": "AaOM7Gi9DC6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На диске должен был появиться каталог `lightning_logs` в нем Lightning сохранил значения метрик которые мы передавали в метод log.\n",
        "\n",
        "По умолчанию используется формат логов [Tensorboard](https://github.com/Gan4x4/ml_snippets/blob/main/Training/Tensorboard.ipynb) но можно использовать и другой logger, например [WandB](https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.WandbLogger.html#lightning.pytorch.loggers.WandbLogger)."
      ],
      "metadata": {
        "id": "7p72-Yo2CAjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colab magic command, run only once\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "L22VgPXQC8d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При запуске Tensorboad мы должны указать путь к каталогу с логами:"
      ],
      "metadata": {
        "id": "6Sg0zw2SDKzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %reload_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir lightning_logs"
      ],
      "metadata": {
        "id": "j9YT9MYDDATG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation\n",
        "\n",
        "Тепперь добавим методы для валидации. Метрику можно было бы оставить и одну, но что бы не запутаться и не забыть ее очистить сосдадим для валидации новую метрику."
      ],
      "metadata": {
        "id": "B3_3Dt9cDbjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitWithVal(LitWithMetric):\n",
        "  def __init__(self, model):\n",
        "      super().__init__(model)\n",
        "      self.val_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      out = self.model(x)\n",
        "      self.val_metric.update(out, y)\n",
        "\n",
        "  def on_validation_epoch_end(self):\n",
        "      self.log(\"accuracy/val\", self.val_metric.compute(), prog_bar=True)\n",
        "      self.val_metric.reset()"
      ],
      "metadata": {
        "id": "cTBmKZSuDj1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так же можно использовать функцию для фиксации seed"
      ],
      "metadata": {
        "id": "aNv86jB5EQ69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(42)\n",
        "model = SimpleModel()\n",
        "lit_model =  LitWithVal(model)\n",
        "trainer = L.Trainer(max_epochs=3) # def on_validation_epoch_start(self):\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "34ENwK82EQDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n",
        "\n",
        "Аналогично добавляются методы для прогона на тестовом датасете. Так как тестовый прогон запускается независимо от обучающего, можем использовать уже имеющуюся в классе метрику.\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule.test_step\n",
        "\n",
        "https://pytorch-lightning.readthedocs.io/en/1.4.9/common/test_set.html"
      ],
      "metadata": {
        "id": "R8eg3D_wsy_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitWithTest(LitWithMetric):\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.metric.update(out, y)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log(\"accuracy/test\", self.metric.compute(), prog_bar=True)\n",
        "        self.metric.reset()"
      ],
      "metadata": {
        "id": "fu68IcgEEuBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сначала обучим:"
      ],
      "metadata": {
        "id": "6HtDAT3pFy4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()\n",
        "lit_model =  LitWithTest(model)\n",
        "trainer = L.Trainer(max_epochs=3) # def on_validation_epoch_start(self):\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "Go4LQLQzF2s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "А затем протестируем обученую модель, вызвав метод `train`."
      ],
      "metadata": {
        "id": "2lwwzI-oF3QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test( model=lit_model, dataloaders=test_loader, verbose=True)"
      ],
      "metadata": {
        "id": "0l8ddBeIFyAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lightning автоматически сохраняет checkpoints с разными состояниями модели. Можно провести тест на лучшем из них."
      ],
      "metadata": {
        "id": "bBbTmv9MGJMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best checkpoint automatically (lightning tracks this for you)\n",
        "trainer.test(\n",
        "    model=lit_model, dataloaders=test_loader,  ckpt_path=\"best\"\n",
        ")"
      ],
      "metadata": {
        "id": "WRE7xsfoGZDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shadow work\n",
        "\n",
        "\n",
        "* managing devices\n",
        "* creating checkpoints\n",
        "* finding LR\n",
        "\n",
        "Standartize\n",
        "\n",
        "* train loop creation\n",
        "* logging\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UiNzffuAu8iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment naming\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.TensorBoardLogger.html#lightning.pytorch.loggers.TensorBoardLogger"
      ],
      "metadata": {
        "id": "nr0WuGVJkphJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "           log_every_n_steps = 1,"
      ],
      "metadata": {
        "id": "rtwLK_S68vN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logger setup\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "LeD7M3pLrBox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
        "trainer = Trainer(logger=logger)"
      ],
      "metadata": {
        "id": "zOMr2KFwrP5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log two variable in one axxis"
      ],
      "metadata": {
        "id": "LJdRUuSG68j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://stackoverflow.com/questions/66287075/pytorch-lightning-multiple-scalars-e-g-train-and-valid-loss-in-same-tensorbo"
      ],
      "metadata": {
        "id": "GL22gB7O67YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint\n",
        "- переименовывать ключи\n",
        "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
      ],
      "metadata": {
        "id": "lL71JoIokkw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
      ],
      "metadata": {
        "id": "L60HoJ5ckmvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning rate\n",
        "\n",
        "https://lightning.ai/docs/pytorch/2.1.0/advanced/training_tricks.html#learning-rate-finder"
      ],
      "metadata": {
        "id": "8x-xd9aAlsEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно"
      ],
      "metadata": {
        "id": "ned0RUGj6XsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abrcbhetv seed"
      ],
      "metadata": {
        "id": "pZ7GZCA16as6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(42)"
      ],
      "metadata": {
        "id": "JQLaaSEc6dy6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}