{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gan4x4/ml_snippets/blob/main/Training/Lightning.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "aRsUXgDyWyxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch pipeline\n",
        "При работе с Pytorch базовый pipeline обучения выглядит примерно так"
      ],
      "metadata": {
        "id": "1AzwsFBHj1Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных"
      ],
      "metadata": {
        "id": "ghuA6uxNkPbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.13), (0.3))]\n",
        ")\n",
        "\n",
        "mnist = datasets.MNIST(root=\"./\", train=True, download=True, transform=transform)\n",
        "\n",
        "# Reduce size of dataset to speedup training\n",
        "train_set, val_set, _ = torch.utils.data.random_split(mnist, [10000, 3000, 47000])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True , num_workers=2)"
      ],
      "metadata": {
        "id": "FpMUerKNk1xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание модели"
      ],
      "metadata": {
        "id": "5aZ0NP8bkSBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,10)\n",
        "        )"
      ],
      "metadata": {
        "id": "_1BAfbF4lKTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Код для валидации"
      ],
      "metadata": {
        "id": "PIclHzagBjCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "@torch.inference_mode()  # this annotation disable grad computation\n",
        "def validate(model, test_loader):\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in test_loader:\n",
        "        pred = model(imgs.to(device))\n",
        "        total += labels.size(0)\n",
        "        _, predicted = torch.max(pred.data, 1) #shape = batch_size, class_count\n",
        "        correct_predictions =  (predicted.cpu() == labels.cpu()).sum()\n",
        "        correct += correct_predictions.sum().item()\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "ZW_Rh5-OBe3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение (train loop)"
      ],
      "metadata": {
        "id": "_wzoMn0hkXXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Q1vOuQymAI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "# managing device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  # Weight update\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in train_loader:\n",
        "    # Processing one batch\n",
        "    imgs, labels = batch\n",
        "    optimizer.zero_grad()\n",
        "    out = model(imgs)\n",
        "    loss = criterion(out, labels.to(device))\n",
        "    loss.backward()\n",
        "\n",
        "    # Calclulate metrics: TODO\n",
        "    # Save metrics to logs:  TODO\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  # Validation step\n",
        "  print(f\"Epoch {epoch} accuracy: {validate(model,val_loader):.2f}\")\n",
        "  # Save checkpoint: TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "OauBrQB6kbea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I65TUcLx1dIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lightning\n",
        "\n",
        "При обучении моделей в pytorch нам часто приходиться переписовать цикл обучения (train loop) это дублирование кода, которое нарушает принцип [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself).\n",
        "\n",
        "Кроме того нам нужно следить за процессом обучения модели, например если loss взрываться или выходит на плато как правило есть смысл остановить обучение. Чтобы контролировать этот процесс приходиться добавлять дополнительный код для вывода и/или логгирования метрик.\n",
        "\n",
        "При проведении реальных экспериментов логирование результатов станет необходимым. Фреймворк ([Lightning](https://lightning.ai/)) облегчает написание tain loop, логирование результатов, и выполняет за нас ряд других задач."
      ],
      "metadata": {
        "id": "Ls417pKb1ZyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "7a9FInFA4lEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train loop в Lightning\n",
        "Базовая задача которую решает Lightning это реализация train loop.\n",
        "\n",
        "Типичный цикл обучения разбит на фрагменты каждый из которых помещен в соответствующий метод класса LightningModule."
      ],
      "metadata": {
        "id": "QNnxNZpcYXCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB69ND0f5LPZ"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "class LitBasic(L.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        print(\"on_train_epoch_start\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        #print(\"training_step\")\n",
        "        pass\n",
        "        #return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        print(\"on_validation_epoch_start\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        #print(\"validation_step\")\n",
        "        pass\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(\"on_validation_epoch_end\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        print(\"on_train_epoch_end\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        print(\"configure_optimizers\")\n",
        "        #return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что бы воспользоваться таким модулем надо передать его в объект класса Trainer"
      ],
      "metadata": {
        "id": "tkoD-wDq526t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#L.seed_everything(42)\n",
        "lit_model = LitBasic()\n",
        "trainer = L.Trainer(max_epochs=1)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "85jZqswI6QBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, один цикл валидации запускается до до начала эпохи обучения, а затем повторяеттся внутри каждой эпохи.\n",
        "\n",
        "Отключить первый вызов валидации можно инициализировав Trainer c параметром num_sanity_val_steps=0"
      ],
      "metadata": {
        "id": "8jrMrIx485KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitBasic()\n",
        "trainer = L.Trainer(max_epochs=1,\n",
        "                    num_sanity_val_steps=0 # disable vlidation before first epoch\n",
        "                    )\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "gml_guMK9iQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Перепишем цикл обучения из на Lightning.\n"
      ],
      "metadata": {
        "id": "GuXMOVaL9xKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель мы можем не менять, достаточно сохранить на не ссылку при инициализации.\n",
        "После этого можно инициализировать оптимизатор и перенести чать кода в train_step"
      ],
      "metadata": {
        "id": "oA5DSIHO-csG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitMinimal(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
        "        return optimizer\n",
        ""
      ],
      "metadata": {
        "id": "awWISGWJ-79v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При создании оптимизатора мы передаем ему не параметры модели, а параметры всего модуля, поэтом не важно как будет называться свойство содержащее ссылку на модель.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOqGoXGV_Xom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitMinimal(model)\n",
        "trainer = L.Trainer(max_epochs=1)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "Sy-A5FDRAItI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код выше минимально необходимый для обучения, он незначительно упрощает создание train_loop о в нем нет методов для оценки точности или вывода графика loss."
      ],
      "metadata": {
        "id": "aKML6apdASx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вычисление метрик"
      ],
      "metadata": {
        "id": "CmftzNO3BC7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "           log_every_n_steps = 1,"
      ],
      "metadata": {
        "id": "rtwLK_S68vN1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvEoXl6ukfA0"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "class LitBasic(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.m = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        self.metric.reset()\n",
        "        print(\"on_train_epoch_start\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        x, y = batch\n",
        "        out = self.m(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.metric.update(out, y)\n",
        "        self.log(\"loss\", loss,prog_bar = True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        print(\"on_validation_epoch_start\")\n",
        "        self.log(\"accuracy/train\", self.metric.compute(),prog_bar = True)\n",
        "        self.metric.reset()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # this is the validation loop\n",
        "        x, y = batch\n",
        "        out = self.m(x)\n",
        "        self.metric.update(out,y)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(\"on_validation_epoch_end\")\n",
        "        self.log(\"accuracy/val\", self.metric.compute(),prog_bar = True)\n",
        "        self.metric.reset()\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        print(\"on_train_epoch_end\")\n",
        "\n",
        "    \"\"\"          optimizers \"\"\"\n",
        "    #def configure_optimizers(self):\n",
        "    #    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "    #    return optimizer\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://pytorch-lightning.readthedocs.io/en/1.7.2/common/lightning_module.html#hooks"
      ],
      "metadata": {
        "id": "RCFpHPh-mv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "from torch import optim\n",
        "import torchmetrics\n",
        "\n",
        "class LitCNN(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.metric = torchmetrics.classification.MulticlassAccuracy(10)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.metric.update(out,y)\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"accuracy/train\", self.accuracy_train.compute())\n",
        "        self.accuracy_train.reset()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"accuracy/val\", self.accuracy_val.compute())\n",
        "        self.accuracy_val.reset()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.accuracy_val.update(out, y)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "1sfSBQ2GZvZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shadow work\n",
        "\n",
        "\n",
        "* managing devices\n",
        "* creating checkpoints\n",
        "* finding LR\n",
        "\n",
        "Standartize\n",
        "\n",
        "* train loop creation\n",
        "* logging\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UiNzffuAu8iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment naming\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.TensorBoardLogger.html#lightning.pytorch.loggers.TensorBoardLogger"
      ],
      "metadata": {
        "id": "nr0WuGVJkphJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logger setup\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "LeD7M3pLrBox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
        "trainer = Trainer(logger=logger)"
      ],
      "metadata": {
        "id": "zOMr2KFwrP5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log two variable in one axxis"
      ],
      "metadata": {
        "id": "LJdRUuSG68j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://stackoverflow.com/questions/66287075/pytorch-lightning-multiple-scalars-e-g-train-and-valid-loss-in-same-tensorbo"
      ],
      "metadata": {
        "id": "GL22gB7O67YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint\n",
        "- переименовывать ключи\n",
        "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
      ],
      "metadata": {
        "id": "lL71JoIokkw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
      ],
      "metadata": {
        "id": "L60HoJ5ckmvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning rate\n",
        "\n",
        "https://lightning.ai/docs/pytorch/2.1.0/advanced/training_tricks.html#learning-rate-finder"
      ],
      "metadata": {
        "id": "8x-xd9aAlsEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule.test_step\n",
        "\n",
        "https://pytorch-lightning.readthedocs.io/en/1.4.9/common/test_set.html"
      ],
      "metadata": {
        "id": "R8eg3D_wsy_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно"
      ],
      "metadata": {
        "id": "ned0RUGj6XsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abrcbhetv seed"
      ],
      "metadata": {
        "id": "pZ7GZCA16as6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(42)"
      ],
      "metadata": {
        "id": "JQLaaSEc6dy6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
