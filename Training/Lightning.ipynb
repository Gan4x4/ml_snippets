{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/github.com/Gan4x4/ml_snippets/blob/main/Training/Lightning.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "aRsUXgDyWyxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch pipeline\n",
        "При работе с Pytorch базовый pipeline обучения выглядит примерно так"
      ],
      "metadata": {
        "id": "1AzwsFBHj1Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных"
      ],
      "metadata": {
        "id": "ghuA6uxNkPbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, utils\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.13), (0.3))]\n",
        ")\n",
        "\n",
        "mnist = datasets.MNIST(root=\"./\", train=True, download=True, transform=transform)\n",
        "\n",
        "# Reduce size of dataset to speedup training\n",
        "train_set, val_set, _ = torch.utils.data.random_split(mnist, [10000, 3000, 47000])\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=False, num_workers=2)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True , num_workers=2)"
      ],
      "metadata": {
        "id": "FpMUerKNk1xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание модели"
      ],
      "metadata": {
        "id": "5aZ0NP8bkSBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.core = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,10)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.core(x)"
      ],
      "metadata": {
        "id": "_1BAfbF4lKTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()"
      ],
      "metadata": {
        "id": "t35IC1LViZIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Код для валидации"
      ],
      "metadata": {
        "id": "PIclHzagBjCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "@torch.inference_mode()  # this annotation disable grad computation\n",
        "def validate(model, test_loader,device):\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in test_loader:\n",
        "        pred = model(imgs.to(device))\n",
        "        total += labels.size(0)\n",
        "        _, predicted = torch.max(pred.data, 1) #shape = batch_size, class_count\n",
        "        correct_predictions =  (predicted.cpu() == labels.cpu()).sum()\n",
        "        correct += correct_predictions.sum().item()\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "ZW_Rh5-OBe3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение (train loop)"
      ],
      "metadata": {
        "id": "_wzoMn0hkXXB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Q1vOuQymAI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "# managing device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = SimpleModel()\n",
        "model.to(device)\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # Weight update\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch in train_loader:\n",
        "    # Processing one batch\n",
        "    imgs, labels = batch\n",
        "    optimizer.zero_grad()\n",
        "    out = model(imgs)\n",
        "    loss = criterion(out, labels.to(device))\n",
        "    loss.backward()\n",
        "\n",
        "    # Calclulate metrics: TODO\n",
        "    # Save metrics to logs:  TODO\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  # Validation step\n",
        "  print(f\"Epoch {epoch} accuracy: {validate(model,val_loader,device):.2f}\")\n",
        "  # Save checkpoint: TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "OauBrQB6kbea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.13), (0.3))]\n",
        ")\n",
        "testset = datasets.MNIST(root=\"./\", train=False, download=True, transform = test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=True)\n",
        "accuracy = validate(model, test_loader, device)\n",
        "\n",
        "print(f\"Accuracy on TEST {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "iDxP0BEOi29H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lightning\n",
        "\n",
        "При обучении моделей в pytorch нам часто приходиться переписовать цикл обучения (train loop) это дублирование кода, которое нарушает принцип [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself).\n",
        "\n",
        "Кроме того нам нужно следить за процессом обучения модели, например если loss взрываться или выходит на плато как правило есть смысл остановить обучение. Чтобы контролировать этот процесс приходиться добавлять дополнительный код для вывода и/или логгирования метрик.\n",
        "\n",
        "При проведении реальных экспериментов логирование результатов станет необходимым. Фреймворк ([Lightning](https://lightning.ai/)) облегчает написание tain loop, логирование результатов, и выполняет за нас ряд других задач."
      ],
      "metadata": {
        "id": "Ls417pKb1ZyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "7a9FInFA4lEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train loop в Lightning\n",
        "Базовая задача которую решает Lightning это реализация train loop.\n",
        "\n",
        "Типичный цикл обучения разбит на фрагменты каждый из которых помещен в соответствующий метод класса LightningModule."
      ],
      "metadata": {
        "id": "QNnxNZpcYXCA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB69ND0f5LPZ"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "class LitDemo(L.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        print(\"configure_optimizers\")\n",
        "        #return optimizer\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        print(\"on_train_epoch_start\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        #print(\"training_step\")\n",
        "        pass\n",
        "        #return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        # called only if validation_step implemented\n",
        "        print(\"on_validation_epoch_start\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        #print(\"validation_step\")\n",
        "        pass\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(\"on_validation_epoch_end\")\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        print(\"on_train_epoch_end\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что бы воспользоваться таким модулем надо передать его в объект класса Trainer"
      ],
      "metadata": {
        "id": "tkoD-wDq526t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#L.seed_everything(42)\n",
        "lit_model = LiDemo()\n",
        "trainer = L.Trainer(max_epochs=1)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "85jZqswI6QBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, один цикл валидации запускается до до начала эпохи обучения, а затем повторяеттся внутри каждой эпохи.\n",
        "\n",
        "Отключить первый вызов валидации можно инициализировав Trainer c параметром num_sanity_val_steps=0"
      ],
      "metadata": {
        "id": "8jrMrIx485KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitDemo()\n",
        "trainer = L.Trainer(max_epochs=1,\n",
        "                    num_sanity_val_steps=0 # disable vlidation before first epoch\n",
        "                    )\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "gml_guMK9iQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Перепишем цикл обучения из на Lightning.\n"
      ],
      "metadata": {
        "id": "GuXMOVaL9xKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель мы можем не менять, достаточно сохранить на не ссылку при инициализации.\n",
        "Нужно инициализировать оптимизатор и перенести чать кода в train_step"
      ],
      "metadata": {
        "id": "oA5DSIHO-csG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitMinimal(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01,momentum =0.9)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "awWISGWJ-79v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При создании оптимизатора мы передаем ему не параметры модели, а параметры всего модуля, поэтом не важно как будет называться свойство содержащее ссылку на модель.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOqGoXGV_Xom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model = LitMinimal(model)\n",
        "trainer = L.Trainer(max_epochs=1)\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "Sy-A5FDRAItI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код выше минимально необходимый для обучения, он незначительно упрощает создание train_loop\n",
        "\n",
        "При этом фреймворк самостоятельно:\n",
        "- обновляет веса модели\n",
        "- сохраняет checkpoints на диск\n",
        "\n",
        " в нем нет методов для оценки точности или вывода графика loss."
      ],
      "metadata": {
        "id": "aKML6apdASx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вычисление метрик\n",
        "\n",
        "Для выисления метрик установим пакет [torchmetrics](https://torchmetrics.readthedocs.io/en/stable/)"
      ],
      "metadata": {
        "id": "CmftzNO3BC7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "sXKpoPyAjyWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики это объекты"
      ],
      "metadata": {
        "id": "nZf54vbRyWhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "# Basic usage\n",
        "preds = torch.tensor([1.,2.,3.])\n",
        "labels = torch.tensor([1,2,9])\n",
        "print(\"Accuracy\",accuracy_metric(preds,labels))\n"
      ],
      "metadata": {
        "id": "UFsyT76Syjcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Они могут накапливать данные а потом вычислять занчение метрики."
      ],
      "metadata": {
        "id": "sf5CTFXtzxQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy\",accuracy_metric.compute()) # old values stored in memory"
      ],
      "metadata": {
        "id": "AFP8pqw20fv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если они не нужны следует их очистить"
      ],
      "metadata": {
        "id": "lfmK0k4y0nUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric.reset() # lear old values\n",
        "print(\"Accuracy\",accuracy_metric.compute())"
      ],
      "metadata": {
        "id": "sh5f_QWI0slf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  preds = torch.randint(0,10,(256,10)).float() # batch predictions\n",
        "  labels = torch.randint(0,10,(256,)) # batch labels\n",
        "  accuracy_metric.update(preds,labels)\n",
        "\n",
        "print(\"Accuracy\",accuracy_metric.compute())\n",
        "accuracy_metric.reset()"
      ],
      "metadata": {
        "id": "G2pdwb5gz0c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Логиррование в Lightning\n",
        "\n",
        "Добавим подсчет метрики в lightning модуль. Будем добавлять значения в метрику при обработке каждого batch.\n",
        "\n",
        "Выводить значения метрики будем в конце каждой эпохи обучения.\n",
        "\n",
        "Для сохранения значений (метрик и любых других) в lightning модуле реализован метод `log`. Используем его так же для согранения loss на каждом batch.\n",
        "\n",
        "Что бы последнее значение отображалось в progress bar установим параметр `prog_bar = True`"
      ],
      "metadata": {
        "id": "yD8vZ1OE5ROW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LitWithMetric(LitMinimal):\n",
        "  def __init__(self, model):\n",
        "      super().__init__(model)\n",
        "      self.metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      out = self.model(x)\n",
        "      loss = self.criterion(out, y)\n",
        "      self.metric.update(out, y)\n",
        "      self.log(\"loss\", loss,prog_bar = True)\n",
        "      return loss\n",
        "\n",
        "  def on_train_epoch_end(self):\n",
        "      self.log(\"accuracy/train\", self.metric.compute(),prog_bar = True)\n",
        "      self.metric.reset()\n"
      ],
      "metadata": {
        "id": "obLP1mVs5hWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleModel()\n",
        "lit_model = LitWithMetric(model)\n",
        "trainer = L.Trainer(max_epochs=3) # def on_validation_epoch_start(self):\n",
        "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders= val_loader)"
      ],
      "metadata": {
        "id": "K6p9Hg0s6rkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvEoXl6ukfA0"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "import torchmetrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class LitBasic(L.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.m = model\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
        "\n",
        "    def on_train_epoch_start(self):\n",
        "        self.metric.reset()\n",
        "        print(\"on_train_epoch_start\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        x, y = batch\n",
        "        out = self.m(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.metric.update(out, y)\n",
        "        self.log(\"loss\", loss,prog_bar = True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_start(self):\n",
        "        print(\"on_validation_epoch_start\")\n",
        "        self.log(\"accuracy/train\", self.metric.compute(),prog_bar = True)\n",
        "        self.metric.reset()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # this is the validation loop\n",
        "        x, y = batch\n",
        "        out = self.m(x)\n",
        "        self.metric.update(out,y)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        print(\"on_validation_epoch_end\")\n",
        "        self.log(\"accuracy/val\", self.metric.compute(),prog_bar = True)\n",
        "        self.metric.reset()\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        print(\"on_train_epoch_end\")\n",
        "\n",
        "    \"\"\"          optimizers \"\"\"\n",
        "    #def configure_optimizers(self):\n",
        "    #    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "    #    return optimizer\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "           log_every_n_steps = 1,"
      ],
      "metadata": {
        "id": "rtwLK_S68vN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://pytorch-lightning.readthedocs.io/en/1.7.2/common/lightning_module.html#hooks"
      ],
      "metadata": {
        "id": "RCFpHPh-mv_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning.pytorch as pl\n",
        "from torch import optim\n",
        "import torchmetrics\n",
        "\n",
        "class LitCNN(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.metric = torchmetrics.classification.MulticlassAccuracy(10)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.metric.update(out,y)\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"accuracy/train\", self.accuracy_train.compute())\n",
        "        self.accuracy_train.reset()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"accuracy/val\", self.accuracy_val.compute())\n",
        "        self.accuracy_val.reset()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        self.accuracy_val.update(out, y)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "1sfSBQ2GZvZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shadow work\n",
        "\n",
        "\n",
        "* managing devices\n",
        "* creating checkpoints\n",
        "* finding LR\n",
        "\n",
        "Standartize\n",
        "\n",
        "* train loop creation\n",
        "* logging\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UiNzffuAu8iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment naming\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.TensorBoardLogger.html#lightning.pytorch.loggers.TensorBoardLogger"
      ],
      "metadata": {
        "id": "nr0WuGVJkphJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logger setup\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ],
      "metadata": {
        "id": "LeD7M3pLrBox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")\n",
        "trainer = Trainer(logger=logger)"
      ],
      "metadata": {
        "id": "zOMr2KFwrP5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log two variable in one axxis"
      ],
      "metadata": {
        "id": "LJdRUuSG68j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://stackoverflow.com/questions/66287075/pytorch-lightning-multiple-scalars-e-g-train-and-valid-loss-in-same-tensorbo"
      ],
      "metadata": {
        "id": "GL22gB7O67YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint\n",
        "- переименовывать ключи\n",
        "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
      ],
      "metadata": {
        "id": "lL71JoIokkw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://lightning.ai/docs/pytorch/stable/common/checkpointing_basic.html"
      ],
      "metadata": {
        "id": "L60HoJ5ckmvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Learning rate\n",
        "\n",
        "https://lightning.ai/docs/pytorch/2.1.0/advanced/training_tricks.html#learning-rate-finder"
      ],
      "metadata": {
        "id": "8x-xd9aAlsEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule.test_step\n",
        "\n",
        "https://pytorch-lightning.readthedocs.io/en/1.4.9/common/test_set.html"
      ],
      "metadata": {
        "id": "R8eg3D_wsy_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительно"
      ],
      "metadata": {
        "id": "ned0RUGj6XsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Abrcbhetv seed"
      ],
      "metadata": {
        "id": "pZ7GZCA16as6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L.seed_everything(42)"
      ],
      "metadata": {
        "id": "JQLaaSEc6dy6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}