{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOvKytE5Sk4mLc7tXBiVLSc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Information Entropy"],"metadata":{"id":"aafWo9WVu0Vx"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sr2DIDi5s0j2","executionInfo":{"status":"ok","timestamp":1694980396027,"user_tz":-180,"elapsed":257,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"36a7be65-ec88-45d2-9a72-a779c4ba7504"},"outputs":[{"output_type":"stream","name":"stdout","text":["8 1.0\n"]}],"source":["import numpy as np\n","\n","p = np.array([1/8,1/8,1/8,1/8,1/8,1/8,1/8,1/8])\n","print(len(p),sum(p))"]},{"cell_type":"code","source":["q = np.array([7/8,1/56,1/56,1/56,1/56,1/56,1/56,1/56])\n","print(len(q),sum(q))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJTBKkzSs_yn","executionInfo":{"status":"ok","timestamp":1694980429768,"user_tz":-180,"elapsed":283,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"b2578f43-3a85-43a0-d819-42902352cc5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8 1.0000000000000002\n"]}]},{"cell_type":"code","source":["def H(p):\n","  return -np.sum(p*np.log2(p))"],"metadata":{"id":"gR51UtZItPEd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(H(p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"quuCqqvRtp8X","executionInfo":{"status":"ok","timestamp":1694980711527,"user_tz":-180,"elapsed":271,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"17b555cf-6e59-458a-9f54-c9cf8b530854"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.0\n"]}]},{"cell_type":"code","source":["print(H(q))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHhVvinbuS-y","executionInfo":{"status":"ok","timestamp":1694980734070,"user_tz":-180,"elapsed":14,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"329e8dc4-13e4-48e1-adbe-ab33d0941e4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.894483808456797\n"]}]},{"cell_type":"markdown","source":["Cross entropy"],"metadata":{"id":"MPTR_MOiuZgb"}},{"cell_type":"code","source":["def CrossH(p,q):\n","  return -np.sum(p*np.log2(q))"],"metadata":{"id":"n-5xeezpuc4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(CrossH(p,q))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9ZcbEVJu0bE","executionInfo":{"status":"ok","timestamp":1694980867528,"user_tz":-180,"elapsed":295,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"b5b943ec-70cb-4352-cc8c-4510fbc8a0dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5.105516191543204\n"]}]},{"cell_type":"code","source":["print(CrossH(q,p))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LE3aafSxuYl","executionInfo":{"status":"ok","timestamp":1694981623326,"user_tz":-180,"elapsed":499,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"594bc1d3-c4f9-4d72-f0c0-e184241b6c84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.0\n"]}]},{"cell_type":"code","source":["def D_KL(p,q):\n","  return CrossH(p,q) - H(p)"],"metadata":{"id":"cPtswra5yOXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(D_KL(p,q))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLGTLMCeywNG","executionInfo":{"status":"ok","timestamp":1694981990893,"user_tz":-180,"elapsed":15,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"7fa84a1c-469e-40fd-dba9-c02eba11d449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.105516191543204\n"]}]},{"cell_type":"code","source":["print(H(p) - H(q))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xqRnRyyIy-cq","executionInfo":{"status":"ok","timestamp":1694982007301,"user_tz":-180,"elapsed":273,"user":{"displayName":"Антон Ганичев","userId":"03960392406657956647"}},"outputId":"bf224e03-f205-432d-ecb3-27b09bd3c53a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.1055161915432032\n"]}]},{"cell_type":"markdown","source":["#Derivative of CE loss"],"metadata":{"id":"qDcfQcrlFWWc"}},{"cell_type":"markdown","source":["$\\bar{s}= Ẇ \\cdot \\bar{x}$ - vector of scores\n","\n","$\\bar{p} = Softmax(\\bar{s}) $\n","\n","\n","$ p_i =\\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}} $ : Where $y_i$ -  class number.\n","\n","For for simplicity, we denote ground true class ${y_i}$ as $t$ and probability for true class as:\n","$ p_t =\\dfrac {e^{s_t}} {\\sum_j e^{s_j}}$\n","\n","\n"],"metadata":{"id":"59hBoLFFHL1z"}},{"cell_type":"markdown","source":["### Loss for one sample"],"metadata":{"id":"srBHK8KrJuno"}},{"cell_type":"markdown","source":["$L = -log(p_t)$  ($p_t$ prediction for ground true class)"],"metadata":{"id":"q-kq20lJKmKL"}},{"cell_type":"markdown","source":["$L = f(s(W))$\n","\n","since $p_t$ is a function of $s$ we can denote $-log(p_t(s))$ as $f(s)$ and apply [chain rule](https://en.wikipedia.org/wiki/Chain_rule): $ \\dfrac {\\partial L} {\\partial W} = \\dfrac {\\partial f} {\\partial s}  \\dfrac {\\partial s} {\\partial W}  $\n","\n","\n","\n"],"metadata":{"id":"b3YdIaQBKzoU"}},{"cell_type":"markdown","source":["Derivative of linear part is:\n","$\\dfrac {\\partial s} {\\partial W}   = \\dfrac {\\partial Wx} {\\partial W}  = x$"],"metadata":{"id":"7DDHNX0WNcmg"}},{"cell_type":"markdown","source":["Remains : $\\dfrac {\\partial f} {\\partial s} = -\\log (\\dfrac {e^{s_{y_i}}} {\\sum_j e^{s_{y_j}}} )$\n","\n","Let's denote it as: $L_{part} = -\\log (\\dfrac {e^{s_t}} {\\sum_j e^{s_j}} )$"],"metadata":{"id":"r-NKjpi1N1Uv"}},{"cell_type":"markdown","source":["### Simplify the expression"],"metadata":{"id":"Rc5kuZSxkT9y"}},{"cell_type":"markdown","source":["**step1**\n","Let's change the base of the logarithm\n","\n","\n","$log_{2}(p) = \\frac{log_{e}(p)}{log_{e}(2)}=\\frac{1}{ln(2)}  ln(p)$  because\n","$\\frac{1}{ln(2)}$ - is a constant we can omit it\n","\n"],"metadata":{"id":"KDnLc9JaOQRp"}},{"cell_type":"markdown","source":["**step2**\n","Replace division by the difference:\n","\n","because of: $\\log(a/b) = \\log(a) - \\log(b)$\n","\n","$L_{part} = -\\ln (\\dfrac {e^{s_t}} {\\sum_j e^{s_j}} ) = -(ln(e^{s_t}) - ln(\\sum_j e^{s_j})) =  ln(\\sum_j e^{s_j}) - ln(e^{s_t})$\n"],"metadata":{"id":"EmbqQgiyPEYD"}},{"cell_type":"markdown","source":["logarithm is natural so:\n","$ln(e^{s_t}) = s_t$\n","\n","and:\n","$L_{part} = ln(\\sum_j e^{s_j}) - s_t$"],"metadata":{"id":"HR8zv4CmQ6vi"}},{"cell_type":"markdown","source":["### Taking the derivative"],"metadata":{"id":"-Jue-QmD72Nl"}},{"cell_type":"markdown","source":["Now take the derivative:  $\\dfrac {\\partial L_{part}} {\\partial s} $\n","\n","\n","Because $s$ is vector derivative will be vector to: $\\dfrac {\\partial L_{part}} {\\partial s}  = [\\dfrac {\\partial L_{part}} {\\partial s_0}, \\dfrac {\\partial L_{part}} {\\partial s_1}, ... ,\\dfrac {\\partial L_{part}} {\\partial s_n}]$\n","where the n number of classes\n","\n","\n","\n"],"metadata":{"id":"OqJ68GQLSBsK"}},{"cell_type":"markdown","source":["Consider one coomponent $s_k$ .There two different cases for ${s_k}$:\n","\n","**case 1**:$k \\not= t $  non target class ($t = y_i$)\n","\n","**case 2** :$k = t$  target class\n"],"metadata":{"id":"2QxpihT5kGdZ"}},{"cell_type":"markdown","source":["**Case1. Non target classes**\n","\n","$ \\dfrac {\\partial s_t} {\\partial s_{k}}  == 0 : k \\not =t$\n","\n","so: $\\dfrac {\\partial L_{part}} {\\partial s_k} = \\dfrac {\\partial (ln(\\sum_j e^{s_t}))} {\\partial s_k} : k \\not =y_i$\n","\n"],"metadata":{"id":"n7-X5lDalC2N"}},{"cell_type":"markdown","source":["Denote the expression under the logarithm by $a$ : $a(s) = \\sum_j e^{s_{y_j}}$\n","\n","and apply chain-rule:\n","$ \\dfrac {ln(\\sum_j e^{s_{y_j}})} {\\partial s_k} = \\dfrac {\\partial ln(a)} {\\partial a} \\dfrac {\\partial a(s)} {\\partial s_k}   $\n","\n","Derivative of natural logarithm: $ ln(a)' = \\frac{1}{a} $\n","\n","$\\dfrac {ln(a)} {\\partial a} = \\frac {1} {\\sum_j e^{s_j}}$\n","\n","$\\dfrac {a(s)} {\\partial s_k} =  \\dfrac {\\partial (\\sum_j e^{s_j})} {\\partial s_k}$\n","\n","\n","$\\dfrac {\\partial L_{part}} {\\partial s_k} = \\frac {1} { \\sum_j e^{s_j}} \\dfrac {\\partial (\\sum_j e^{s_j})} {\\partial s_k}$\n","\n","\n","By the derivative property $(a+b)' = a' + b'$\n","\n","$\\dfrac {\\partial (\\sum_j e^{s_j})} {\\partial s_k} = \\dfrac {\\partial \\ e^{s_0}} {\\partial s_k} + \\dfrac {\\partial \\ e^{s_1}} {\\partial s_k} + ... + \\dfrac {\\partial \\ e^{s_n}} {\\partial s_k}$\n","\n","аnd all the elements except $\\dfrac {\\partial \\ e^{s_k}} {\\partial s_k} $ will be equal to zero\n","\n","because of $(e^x)' = e^x$ ,\n","$\\dfrac {\\partial \\ e^{s_k}} {\\partial s_k} = e^{s_k}$\n","\n","and\n","\n","$\\dfrac {\\partial L_{part}} {\\partial s_k} = \\frac {{s_k}} { \\sum_j e^{s_j}} = p_k$\n","\n","so for all elements of $\\dfrac {\\partial L_{part}} {\\partial s}$ except $\\dfrac{\\partial L_{part}} {\\partial s_t}$ we have:\n","\n","$\\dfrac {\\partial L_{part}} {\\partial s}  = [p_0,p_1, ... \\dfrac {\\partial L_{part}} {\\partial s_t}, ... ,p_n]$\n"],"metadata":{"id":"axL2JNKmT6ku"}},{"cell_type":"markdown","source":["*For target class *\n","\n","$L_{part} = ln(\\sum_j e^{s_j}) - s_t$\n","\n","$\\dfrac {\\partial L_{part}} {\\partial s_{t}} =  \\dfrac {\\partial (ln(\\sum_j e^{s_t}))} {\\partial s_t} - \\dfrac {\\partial s_t} {\\partial s_{t}}  = p_t - 1$\n","\n","because of : $ \\dfrac {\\partial s_t} {\\partial s_{k}}  == 1\n","\n","and : $\\dfrac {\\partial (ln(\\sum_j e^{s_t}))} {\\partial s_t} = p_t$ as shown above for any s.\n","\n","\n"],"metadata":{"id":"4nXlU5qlJeyg"}},{"cell_type":"markdown","source":["Finally\n","\n","$\\dfrac {\\partial L_{part}} {\\partial s}  = \\dfrac {\\partial f} {\\partial s} = [p_0,p_1, ... ,p_t-1, ... ,p_n]$\n","\n","and fulll loss: $L =  \\dfrac {\\partial L} {\\partial W} = \\dfrac {\\partial f} {\\partial s}  \\dfrac {\\partial s} {\\partial W} = \\dfrac {\\partial f} {\\partial s} \\cdot x$"],"metadata":{"id":"CXNZY6ZmM-vI"}},{"cell_type":"code","source":[],"metadata":{"id":"w7Ixo7JAN0lz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"YPmt4PQiUo8Q"}}]}