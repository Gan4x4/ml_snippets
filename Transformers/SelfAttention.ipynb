{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Embeddings"
      ],
      "metadata": {
        "id": "SKmjpmfnXKYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get embeddings for texts"
      ],
      "metadata": {
        "id": "N2LQb05GXUbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get embeddings for images"
      ],
      "metadata": {
        "id": "_zkdaQNcXbnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3tkMNTyKvWRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd5f2d0-b0f1-435a-d478-d24292de9d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "img = torch.randn(3,32,32)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image to vector"
      ],
      "metadata": {
        "id": "PRcm_MiYbbMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By conv\n",
        "\n",
        "emb_size = 3\n",
        "conv = torch.nn.Conv2d(3,emb_size,kernel_size= 16, stride = 16 )\n",
        "out = conv(img.unsqueeze(0))\n",
        "feature_map = out.squeeze(0)\n",
        "print(feature_map.shape)\n",
        "sequence = feature_map.flatten(1)\n",
        "print(sequence.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMg9osz1a0NV",
        "outputId": "f722e8ed-9146-406e-f2c3-d151f7282b62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2, 2])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# By MLP\n",
        "# patchify ...\n",
        "\n",
        "fc = torch.nn.Linear(4,64,kernel_size= 8, stride = 8 )\n"
      ],
      "metadata": {
        "id": "grodNMTobjSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Linear layer process 2D input ?"
      ],
      "metadata": {
        "id": "nkq-iIpncOah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.tensor([[1,2],[300,400]],dtype=torch.float)\n",
        "fc = torch.nn.Linear(2,3)\n",
        "\n",
        "out = fc(input.unsqueeze(0))\n",
        "print(out.data,out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZhwf6gQcUt5",
        "outputId": "e0c8096b-dc5e-4c3d-a3a7-d43421e57fef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  -0.2147,   -0.4526,   -0.4532],\n",
            "         [-114.1043, -122.3555,  -51.2447]]]) torch.Size([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-a batch with two dim"
      ],
      "metadata": {
        "id": "yITeWpLNdZIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a sequence"
      ],
      "metadata": {
        "id": "9fX3Smdmd1PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = sequence.permute(1,0)\n",
        "print(sequence.shape) # sequence of 16 embedding size of each emb. is 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UWr0Isdd8Vb",
        "outputId": "acc134f0-cca2-4829-ca3b-d5550fefb4d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now process image embeddings by Linear layer"
      ],
      "metadata": {
        "id": "SM-U24V8fWbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fc = torch.nn.Linear(emb_size,emb_size)\n",
        "values = fc(sequence.unsqueeze(0)).squeeze(0)\n",
        "print(values.shape) # Batch, sequence_len, emb_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELo9hcXffgCl",
        "outputId": "6841abe9-5ef7-4092-9f61-62e7ddb7005a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In MLP we apply non-linearity and repeat this step. But in attention layer we multiply outputs by attention weights and summ it"
      ],
      "metadata": {
        "id": "MV07-1zrd4UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights  = torch.tensor([[ .0, .1, .1, .8],\n",
        "      [ .5, .2, .2, .1],\n",
        "      [ .3, .3, .2, .2]])\n",
        "\n",
        "\n",
        "\n",
        "raw_out = []\n",
        "for a in attention_weights:\n",
        "  print(values.shape,a.shape)\n",
        "  raw_out.append(values * a.T[:,None])\n",
        "raw_out = torch.stack(raw_out)\n",
        "\n",
        "print(raw_out, raw_out.shape)\n",
        "\n",
        "#out = \n",
        "\n",
        "out = values[:,None] * attention_weights.T[:,:,None]\n",
        "print(out)\n",
        "print(out.shape)\n",
        "\n",
        "assert torch.allclose(raw_out.reshape(4,3,3), out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "3l5LleDFhbL3",
        "outputId": "c5499f50-1218-45d3-e701-7784a2d2bb7f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3]) torch.Size([4])\n",
            "torch.Size([4, 3]) torch.Size([4])\n",
            "torch.Size([4, 3]) torch.Size([4])\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0801,  0.0638, -0.0355],\n",
            "         [-0.0528, -0.0531, -0.0446],\n",
            "         [ 0.6027,  0.7206, -0.7645]],\n",
            "\n",
            "        [[ 0.2954,  0.0679,  0.1608],\n",
            "         [ 0.1602,  0.1276, -0.0711],\n",
            "         [-0.1055, -0.1062, -0.0892],\n",
            "         [ 0.0753,  0.0901, -0.0956]],\n",
            "\n",
            "        [[ 0.1772,  0.0408,  0.0965],\n",
            "         [ 0.2403,  0.1913, -0.1066],\n",
            "         [-0.1055, -0.1062, -0.0892],\n",
            "         [ 0.1507,  0.1801, -0.1911]]], grad_fn=<StackBackward0>) torch.Size([3, 4, 3])\n",
            "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.2954,  0.0679,  0.1608],\n",
            "         [ 0.1772,  0.0408,  0.0965]],\n",
            "\n",
            "        [[ 0.0801,  0.0638, -0.0355],\n",
            "         [ 0.1602,  0.1276, -0.0711],\n",
            "         [ 0.2403,  0.1913, -0.1066]],\n",
            "\n",
            "        [[-0.0528, -0.0531, -0.0446],\n",
            "         [-0.1055, -0.1062, -0.0892],\n",
            "         [-0.1055, -0.1062, -0.0892]],\n",
            "\n",
            "        [[ 0.6027,  0.7206, -0.7645],\n",
            "         [ 0.0753,  0.0901, -0.0956],\n",
            "         [ 0.1507,  0.1801, -0.1911]]], grad_fn=<MulBackward0>)\n",
            "torch.Size([4, 3, 3])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-ef12b871812f>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Другая проблемма сверток состоит в том что они слабо учитывают контекст."
      ],
      "metadata": {
        "id": "4cvdelmnTcB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L09/conv_vs_self_attention1.png\"  width=\"700\"></center>\n",
        "\n",
        "Для нас очевидно что на кусте клубники скорее всего окажется еще одна ягода клубники а не малина, вишня или грузовик. "
      ],
      "metadata": {
        "id": "7jiiUjB4Tmfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import MultiheadAttention\n",
        "\n",
        "multihead_attn = nn.MultiheadAttention(embed_dim, num_heads = 1)\n",
        "attn_output, attn_output_weights = multihead_attn(query = dummy_x, key = dummy_x , value =dummy_x)\n",
        "\n",
        "for name, param in multihead_attn.named_parameters():\n",
        "  print(name, param.shape)\n",
        "\n",
        "print(\"Output shape\",attn_output.shape)\n",
        "print(\"Attention weights\",attn_output_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwu6Mt0YrkBQ",
        "outputId": "d038052b-89ab-4b7e-c6c4-fe243fbb150c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in_proj_weight torch.Size([768, 256])\n",
            "in_proj_bias torch.Size([768])\n",
            "out_proj.weight torch.Size([256, 256])\n",
            "out_proj.bias torch.Size([256])\n",
            "Output shape torch.Size([1, 16, 256])\n",
            "Attention weights tensor([[[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]],\n",
            "\n",
            "        [[1.]]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    }
  ]
}